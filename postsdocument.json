[{
  "_id": {
    "$oid": "655ea76528dec0f1f168acc1"
  },
  "title": "How Loosing First Programming Job Helped My Career",
  "photoUrl": "https://images.unsplash.com/photo-1587614387466-0a72ca909e16?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=2100&q=80",
  "body": "Currently, I'm reading \"Same as Ever\" by Morgan Housel. In one chapter, he writes about how adversity often spurs human growth. This chapter took me back six years, to the time when, after quitting the consulting career path and learning for some time, I got my first coding job and lost it soon after.\n\nI'll spare you the details, but the gist is this: after a challenging six months, my journey with the company (let's call it Company A) came to an end, and I was let go. Company A was looking for junior with some more applicable skills, and I was missing those skills. It was a simple mismatch of expectations, but for me, it felt like a small end of the world.\n\nI was lucky enough that the other company (Company B) I previously interviewed for was still interested and wanted to hire me. Before I joined Company A, I took part in demo day at Company B where I worked on simple tasks with more senior developers. I made a good impression, they offered me a job, but I liked the Company A more and decided to go this way. After Company A let me go, Company B was happy to take me in.\n\nI joined Company B with a completely different mindset to the one I had when joining Company A. My imposter syndrome hit the roof, I questioned my choice to change profession. I exaggerated all my mistakes and lost most confidence in my skills and choices. I was under a serious amount of stress and I could feel it.\n\nAt the same time, this challenging period, while tough, was incredibly motivating. Determined not to repeat past mistakes, I dedicated countless hours to learning and becoming self-reliant. I was fortunate to have a CTO who had a great process for training junior developers, and helpful people in my team who patiently tolerated my countless questions. Looking back, I couldn't have asked for a better environment to kick-start my programming career.\n\nEven after gaining independence and confidence in my work, the motivation from those early struggles stuck with me. To this day, I strive to bring value quickly to new teams and make myself useful as soon as possible. I still learn after hours, and try to be better at my profession.\n\nReflecting on it, my experience at Company A was a wake-up call, a mix of fear and realization. I knew I never want to go through something similar again. I'm aware I don't always control everything, but I'm dedicated to do everything I can to make things work, within healthy boundaries.\n\nThis part of my programming journey, though difficult, has been valuable. I'm happy it played this way, it shaped me as a professional, and helped build good habits. It also made me more cautious when interviewing.\n\nIf you are going through something similar remember, however tough and groundbreaking it seems, it's up to you what you will do with it. With a bit of luck and a lot of grid, you can come out stronger on the other side.",
  "category": "Cybersecurity",
  "userId": {
    "$oid": "65431f461d8581fcfea8c76a"
  },
  "author": {
    "name": "Aaron Omale"
  },
  "updatedAt": {
    "$date": "2023-11-30T07:17:03.909Z"
  },
  "createdAt": {
    "$date": "2023-11-23T01:14:13.380Z"
  },
  "href": "how-loosing-first-programming-job-helped-my-career",
  "__v": 0
},
{
  "_id": {
    "$oid": "655eaf8528dec0f1f168ace2"
  },
  "title": "Javascript \"==\" vs \"===\"",
  "photoUrl": "https://images.unsplash.com/photo-1587614387466-0a72ca909e16?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=2100&q=80",
  "body": "Working with javascript you might have encountered, the double and triple equals, operators. People, do get confused on when to use any of these are the any specific cases or what ? In this article let's uncover more about it.\n\nEquality Operator ==\n\nThe == operator is the equality operator in JavaScript.\n\nIt performs type coercion if the operands are of different types, meaning it tries to convert the operands to the same type before making the comparison.\n\nFor example, if you compare a string and a number using ==, JavaScript will attempt to convert the string to a number before making the comparison.\n\nExample:\n\n\nCOPY\n\nCOPY\nconsole.log(5 == '5') // true\nStrict Equality Operator ===\n\nThe === operator is the strict equality operator.\n\nIt does not perform type coercion. It checks both the value and the type of the operands. If they are of different types, the comparison evaluates to false.\n\nThis is considered safer and is generally recommended unless you explicitly want type coercion.\n\nExample:\n\n\nCOPY\n\nCOPY\nconsole.log(5 === '5') // false\nconsole.log(5 === 5) // true\nCommon Pitfalls\nDue to the potential for unexpected results with type coercion, most of the developers prefer using === to avoid subtle bugs. When in doubt, using === is generally a safer choice.\n\nBelow are some examples, showing the difference between === and ==\n\n\nCOPY\n\nCOPY\n0 == false // true, because of type coercion\n0 === false // false, because the types are different\nThe value of 0 when checked with false is same, because 0 and false both have same value in JavaScript, but when checked against type and value, the value is false because 0 is a number and false is boolean. So, here values are same, types are different, that's why we can see the effect of type coercion in this.\n\n\nCOPY\n\nCOPY\nconsole.log(\"\" == false) //true\nconsole.log(\"\" === false) //false\nIn first case == returns true, because in javascript empty string and false is considered equal. Whereas, in second case types are different and hence === returns false.",
  "category": "Frontend",
  "userId": {
    "$oid": "65431f461d8581fcfea8c76a"
  },
  "author": {
    "name": "Aaron Omale"
  },
  "updatedAt": null,
  "createdAt": {
    "$date": "2023-11-23T01:48:53.790Z"
  },
  "href": "javascript-\"\"-vs-\"\"",
  "__v": 0
},
{
  "_id": {
    "$oid": "6567e6a218cfd9fb550df1e0"
  },
  "title": "McKinsey Technology Trends Outlook 2023",
  "photoUrl": "",
  "body": "After a tumultuous 2022 for technology investment and talent, the first half of 2023 has seen a resurgence of enthusiasm about technology’s potential to catalyze progress in business and society. Generative AI deserves much of the credit for ushering in this revival, but it stands as just one of many advances on the horizon that could drive sustainable, inclusive growth and solve complex global challenges.\n\nTo help executives track the latest developments, the McKinsey Technology Council has once again identified and interpreted the most significant technology trends unfolding today. While many trends are in the early stages of adoption and scale, executives can use this research to plan ahead by developing an understanding of potential use cases and pinpointing the critical skills needed as they hire or upskill talent to bring these opportunities to fruition.\n\nOur analysis examines quantitative measures of interest, innovation, and investment to gauge the momentum of each trend. Recognizing the long-term nature and interdependence of these trends, we also delve into underlying technologies, uncertainties, and questions surrounding each trend. This year, we added an important new dimension for analysis—talent. We provide data on talent supply-and-demand dynamics for the roles of most relevance to each trend. (For more, please see the sidebar, “Research methodology.”)",
  "category": "Other",
  "userId": {
    "$oid": "6567e1e718cfd9fb550df1cf"
  },
  "author": {
    "name": "Admin User"
  },
  "updatedAt": null,
  "createdAt": {
    "$date": "2023-11-30T01:34:26.353Z"
  },
  "href": "mckinsey-technology-trends-outlook-2023",
  "__v": 0
},
{
  "_id": {
    "$oid": "656836cbad45bdc1d237559e"
  },
  "title": "What is a UUID?",
  "photoUrl": "https://cdn.hashnode.com/res/hashnode/image/upload/v1701286612864/1dc1c64f-bffd-4c7b-9eeb-59089bc8cb0e.png?w=1600&h=840&fit=crop&crop=entropy&auto=compress,format&format=webp",
  "body": "Understanding UUIDs: Universally Unique Identifiers Explained.\nIntroduction\nUniversally Unique Identifiers (UUIDs) play a crucial role in various computer systems and applications, providing a means to generate unique identifiers with an extremely low probability of collisions. In this article, we'll explore more about UUIDs.\n\nWhat is a UUID?\nA Universally Unique Identifier (UUID) is a 128-bit identifier designed to be globally unique across space and time. To ensure uniqueness, the UUID combines a number of components.\n\nWhich includes, timestamp, randomly generated component, and a reference to the host's network address. The timestamp is unique for every UUID created from a specific host, and the network address uniquely identifies a machine, thus those two factors should be enough to guarantee uniqueness.\n\nUUID Structure\nUUIDs are usually represented as a string of 32 hexadecimal characters, grouped as five sections. The common format is \"8-4-4-4-12,\" where each segment represents the number of bits dedicated to a specific component. The structure may include a timestamp, clock sequence, and node identifier.\nBinary Representation and 128 Bits:\n\nAt its core, a UUID is a 128-bit value, meaning it consists of 128 binary digits (0s and 1s)\n\nSo, each hexadecimal digit represents 4 bits. That's why, a UUID is often presented as a string of 32 hexadecimal characters\n\nIf we do the math, we get 32 characters × 4  bits/character=128 bits or 32 characters × 4 bits/character=128 bits\n\nFor example, consider the UUID: 550e8400-e29b-41d4-a716-446655440000. When converted to binary, it consists of 128 bits\n\nHexadecimal Representation and 32 Characters:\n\nUUIDs are commonly represented as strings of 32 hexadecimal characters (0-9 and a-f)\n\nEach pair of hexadecimal characters equals to 8 bits (4 bits per character × 2 characters). As there are 16 possible values for each character (0-9 and a-f), each pair represents 2^8 = 256 possible combinations\n\nIf we do the math, we get 32 characters => 16 pairs × 8 bits/pair = 128 bits\n\nFor example, in the UUID 550e8400-e29b-41d4-a716-446655440000, each pair of characters represents 8 bits in hexadecimal form\n\nUUID Versions\nThere are several UUID versions, each with its own method of generation. The most commonly used one is UUID v4, which relies on random or pseudo-random numbers for uniqueness. Other versions may incorporate timestamps, MAC addresses, or names.\n\nUse Cases of UUIDs\nWe have highlighted, common use cases for UUIDs, there are a lot more than the below mentioned, do explore then if you want to.\n\nDatabase Primary Keys: UUIDs are widely used as primary keys in databases, ensuring each record has a globally unique identifier without requiring centralized coordination\n\nDistributed Systems: In distributed systems, where data is spread across multiple nodes or servers, UUIDs help generate unique identifiers without the need for a central authority\n\nWeb Development: UUIDs find applications in web development for creating unique identifiers for elements on a page or tracking user sessions\n\nSecurity: UUIDs are employed in security-related scenarios, such as generating unique session tokens or tracking unique software instances",
  "category": "Backend",
  "userId": {
    "$oid": "6567e1e718cfd9fb550df1cf"
  },
  "author": {
    "name": "Admin User"
  },
  "updatedAt": null,
  "createdAt": {
    "$date": "2023-11-30T07:16:27.545Z"
  },
  "href": "what-is-a-uuid",
  "__v": 0
},
{
  "_id": {
    "$oid": "656839cdad45bdc1d23755de"
  },
  "title": "The simplest gateway to mastering the basics of web development",
  "photoUrl": "https://cdn.hashnode.com/res/hashnode/image/upload/v1701104753921/de37e080-8030-4faf-b11b-adb12858d603.jpeg?w=1600&h=840&fit=crop&crop=entropy&auto=compress,format&format=webp",
  "body": "In this article, we will explore some simple and easy front-end techniques that will kickstart your web development journey. We will cover the basics of HTML, CSS, and JavaScript, and provide key takeaways to help you grasp the fundamental concepts. Whether you are a beginner or looking to refresh your skills, this article will provide you with the necessary knowledge to get started in web development.\n\nKey Takeaways\nHTML is the backbone of every web page and consists of tags and elements.\nCSS is used to style and layout web pages, and selectors help target specific elements.\nUnderstanding the CSS box model is crucial for controlling the spacing and sizing of elements.\nJavaScript is a programming language that adds interactivity and dynamic behavior to web pages.\nVariables, data types, functions, and control flow are essential concepts in JavaScript.\nHTML Basics\nIntroduction to HTML\nHTML (Hypertext Markup Language) is the standard markup language used for creating web pages. It provides the structure and content of a webpage by using various tags and elements. Tags are enclosed in angle brackets (<>) and are used to define different elements such as headings, paragraphs, images, links, and more. HTML attributes provide additional information about an element and are added within the opening tag. For example, the href attribute is used to specify the URL of a hyperlink. Understanding the basics of HTML is essential for building web pages and forms the foundation of web development.\n\nHTML provides the structure and content of a webpage.\nTags and elements are used to define different parts of a webpage.\nAttributes provide additional information about an element.\nHTML is like the skeleton of a webpage, providing the structure and framework for other elements to be displayed and interacted with.\n\nHTML Tags and Elements\nHTML tags are used to define the structure and content of a web page. They are enclosed in angle brackets <>. Some commonly used HTML tags include:\n\n<h1> to <h6>: These tags are used to define headings of different levels.\n<p>: This tag is used to define a paragraph.\n<a>: This tag is used to create links.\nIn addition to tags, HTML elements are also used to define the structure of a web page. Some commonly used HTML elements include:\n\n<div>: This element is used to group other elements.\n<img>: This element is used to insert images.\n<table>: This element is used to create tables.\nHTML provides a wide range of tags and elements that allow developers to create well-structured and visually appealing web pages. It is important to understand the purpose and usage of these tags and elements in order to effectively build web pages.\n\nHTML Attributes\nIn HTML, attributes provide additional information about an element. They are used to modify the behavior or appearance of an element. Attributes are placed within the opening tag of an element and consist of a name and a value. Some commonly used attributes include class, id, and style. The class attribute is used to specify one or more class names for an element, which can be used to apply CSS styles. The id attribute is used to uniquely identify an element, while the style attribute is used to apply inline CSS styles to an element. Additionally, HTML5 introduces new attributes such as data-* attributes, which can be used to store custom data within an element. It is important to use attributes correctly and according to their intended purpose to ensure valid and accessible HTML code. Here is an example of how attributes are used in an HTML table:\n\nAttribute\tDescription\ncolspan\tSpecifies the number of columns a cell should span\nrowspan\tSpecifies the number of rows a cell should span\nAttributes play a crucial role in web development as they allow developers to add functionality and style to their HTML elements. Understanding how to use attributes effectively is essential for creating well-structured and visually appealing web pages.\n\nCSS Fundamentals\nIntroduction to CSS\nCSS (Cascading Style Sheets) is a stylesheet language used for describing the look and formatting of a document written in HTML. It allows web developers to separate the presentation of a web page from its structure, making it easier to style and design the page. CSS uses selectors to target specific HTML elements and apply styles to them. The CSS Box Model is an important concept to understand, as it defines the spacing and layout of elements on a web page. CSS provides a wide range of properties and values that can be used to customize the appearance of elements, including colors, fonts, margins, and more. CSS is an essential skill for frontend developers as it allows them to create visually appealing and responsive websites.\n\nBy: Alema Edrick",
  "category": "Frontend",
  "userId": {
    "$oid": "6567e1e718cfd9fb550df1cf"
  },
  "author": {
    "name": "Admin User"
  },
  "updatedAt": null,
  "createdAt": {
    "$date": "2023-11-30T07:29:17.094Z"
  },
  "href": "the-simplest-gateway-to-mastering-the-basics-of-web-development",
  "__v": 0
},
{
  "_id": {
    "$oid": "65683a6ead45bdc1d23755e9"
  },
  "title": "Mastering Navigation with React Router",
  "photoUrl": "https://cdn.hashnode.com/res/hashnode/image/upload/v1701271303649/7683c8dc-a5c9-42b4-88fa-e48cb23c3872.png?w=1600&h=840&fit=crop&crop=entropy&auto=compress,format&format=webp",
  "body": "Navigation is an important part of web development because it allows users to move between different views within a React application in a seamless manner. React Router is a sophisticated toolkit that allows developers to construct dynamic and interactive user interfaces by enabling client-side routing. This article will take you through the basics of React Router, from installation to sophisticated navigation patterns.\n\nGetting Started with React Router\nInstallation\nBefore diving into React Router, let's start by installing it in our project. Open your terminal and run the following command:\n\n\nCOPY\n\nCOPY\nnpm install react-router-dom\nThis will install the necessary dependencies for React Router.\n\nBasic Setup\nOnce installed, let's set up the basic structure of React Router. In your main application file, often named App.js, import the required components from React Router:\n\n\nCOPY\n\nCOPY\n// App.js\n\nimport React from 'react';\nimport { BrowserRouter as Router, Route } from 'react-router-dom';\n\nimport Home from './components/Home';\nimport About from './components/About';\nimport Contact from './components/Contact';\n\nconst App = () => {\n  return (\n    <Router>\n      <div>\n        <Route path=\"/\" exact component={Home} />\n        <Route path=\"/about\" component={About} />\n        <Route path=\"/contact\" component={Contact} />\n      </div>\n    </Router>\n  );\n};\n\nexport default App;\nHere, we've set up a BrowserRouter as Router and defined three routes for the home, about, and contact pages using the Route component.\n\nNavigating with Links\nTo enable navigation between these routes, we can use the Link component. Let's create a Navbar component for our navigation:\n\n\nCOPY\n\nCOPY\n// Navbar.js\n\nimport React from 'react';\nimport { Link } from 'react-router-dom';\n\nconst Navbar = () => {\n  return (\n    <nav>\n      <ul>\n        <li>\n          <Link to=\"/\">Home</Link>\n        </li>\n        <li>\n          <Link to=\"/about\">About</Link>\n        </li>\n        <li>\n          <Link to=\"/contact\">Contact</Link>\n        </li>\n      </ul>\n    </nav>\n  );\n};\n\nexport default Navbar;\nNow, users can navigate between different views using the links provided by the Link component.\n\nRendering Components based on Routes\nLet's create the components for the Home, About, and Contact pages. These components will be rendered when the corresponding route is accessed:\n\n\nCOPY\n\nCOPY\n// Home.js\n\nimport React from 'react';\n\nconst Home = () => {\n  return <div>Welcome to the Home Page!</div>;\n};\n\nexport default Home;\n\nCOPY\n\nCOPY\n// About.js\n\nimport React from 'react';\n\nconst About = () => {\n  return <div>About Us - Learn more about our company!</div>;\n};\n\nexport default About;\n\nCOPY\n\nCOPY\n// Contact.js\n\nimport React from 'react';\n\nconst Contact = () => {\n  return <div>Contact Us - Reach out to us for any inquiries!</div>;\n};\n\nexport default Contact;\nThese components will provide the content for each corresponding route, enhancing the user experience.\n\nNavLink for Stylish Navigation\nReact Router's NavLink component extends the functionality of Link by allowing you to apply styles to the active navigation link. This is especially useful for providing visual feedback to users about the current page.\n\n\nCOPY\n\nCOPY\n// Navbar.js\n\nimport React from 'react';\nimport { NavLink } from 'react-router-dom';\n\nconst Navbar = () => {\n  return (\n    <nav>\n      <ul>\n        <li>\n          <NavLink to=\"/\" exact activeClassName=\"active-link\">\n            Home\n          </NavLink>\n        </li>\n        <li>\n          <NavLink to=\"/about\" activeClassName=\"active-link\">\n            About\n          </NavLink>\n        </li>\n        <li>\n          <NavLink to=\"/contact\" activeClassName=\"active-link\">\n            Contact\n          </NavLink>\n        </li>\n      </ul>\n    </nav>\n  );\n};\n\nexport default Navbar;\nIn this example, the activeClassName prop is used to specify the CSS class applied to the active link. This way, you can easily style the active link to distinguish it from others.\n\nRoute Parameters\nDynamic Routes\nReact Router allows you to create dynamic routes by including parameters in the URL. For example, you might have a route for displaying user profiles where the username is a dynamic parameter.\n\n\nCOPY\n\nCOPY\n// App.js\n\nimport React from 'react';\nimport { BrowserRouter as Router, Route } from 'react-router-dom';\n\nimport UserProfile from './components/UserProfile';\n\nconst App = () => {\n  return (\n    <Router>\n      <div>\n        <Route path=\"/profile/:username\" component={UserProfile} />\n      </div>\n    </Router>\n  );\n};\n\nexport default App;\nHere, the :username in the path indicates a dynamic parameter. Users can access profiles by navigating to URLs like /profile/johndoe or /profile/sarahsmith.\n\nAccessing Route Parameters\nReact Router provides the useParams hook to access parameters from the URL in functional components:\n\n\nCOPY\n\nCOPY\n// UserProfile.js\n\nimport React from 'react';\nimport { useParams } from 'react-router-dom';\n\nconst UserProfile = () => {\n  const { username } = useParams();\n\n  return <div>User Profile for {username}</div>;\n};\n\nexport default UserProfile;\nThe useParams hook allows us to retrieve the dynamic parameter (username) from the URL and use it within the component.\n\nProgrammatic Navigation\nRedirecting Programmatically\nSometimes, you may need to redirect users to a different route based on certain conditions. React Router provides the Redirect component for this purpose.\n\n\nCOPY\n\nCOPY\n// AuthCheck.js\n\nimport React, { useState } from 'react';\nimport { Redirect } from 'react-router-dom';\n\nconst AuthCheck = () => {\n  const [isLoggedIn, setLoggedIn] = useState(false);\n\n  // Check authentication status\n  const isAuthenticated = () => {\n    // Logic to check authentication status\n    return isLoggedIn;\n  };\n\n  return (\n    <div>\n      {isAuthenticated() ? (\n        <p>Welcome to the protected area!</p>\n      ) : (\n        <Redirect to=\"/login\" />\n      )}\n    </div>\n  );\n};\n\nexport default AuthCheck;\nIn this example, if the user is not authenticated, they will be redirected to the login page.\n\nUsing history for Navigation\nReact Router provides the history object, allowing you to navigate programmatically. You can access it through the useHistory hook or the withRouter higher-order component.\n\n\nCOPY\n\nCOPY\n// ProgrammaticNavigation.js\n\nimport React from 'react';\nimport { useHistory } from 'react-router-dom';\n\nconst ProgrammaticNavigation = () => {\n  const history = useHistory();\n\n  const handleNavigate = () => {\n    // Navigate to a different route programmatically\n    history.push('/new-route');\n  };\n\n  return (\n    <div>\n      <p>Click the button to navigate to a new route!</p>\n      <button onClick={handleNavigate}>Navigate</button>\n    </div>\n  );\n};\n\nexport default ProgrammaticNavigation;\nHere, clicking the button triggers the handleNavigate function, which uses history.push to navigate to the specified route.\n\nNested Routes\nCreating Nested Routes\nNested routes in React Router allow you to structure your application with parent and child components, providing a clean and organized hierarchy.\n\n\nCOPY\n\nCOPY\n// ParentComponent.js\n\nimport React from 'react';\nimport { Route, Link } from 'react-router-dom';\nimport ChildComponent from './ChildComponent';\n\nconst ParentComponent = () => {\n  return (\n    <div>\n      <h2>Parent Component</h2>\n      <ul>\n        <li>\n          <Link to=\"/parent/child\">Child Component</Link>\n        </li>\n      </ul>\n      <Route path=\"/parent/child\" component={ChildComponent} />\n    </div>\n  );\n};\n\nexport default ParentComponent;\nIn this example, ParentComponent contains a child route to ChildComponent. Navigating to /parent/child will render the ChildComponent within the ParentComponent layout.\n\nPassing Props to Nested Components\nYou can pass props from a parent component to a child component in a nested route. This is achieved by rendering the child component using the render prop instead of component in the Route.\n\n\nCOPY\n\nCOPY\n// ParentComponent.js\n\nimport React from 'react';\nimport { Route } from 'react-router-dom';\nimport ChildComponent from './ChildComponent';\n\nconst ParentComponent = () => {\n  const additionalProp = 'Hello from Parent!';\n\n  return (\n    <div>\n      <h2>Parent Component</h2>\n      <Route\n        path=\"/parent/child\"\n        render={(props) => (\n          <ChildComponent {...props} additionalProp={additionalProp} />\n        )}\n      />\n    </div>\n  );\n};\n\nexport default ParentComponent;\nHere, additionalProp is passed from the ParentComponent to the ChildComponent.\n\nRoute Guards and Authentication\nRoute Guards\nRoute guards allow you to protect routes based on certain conditions, such as user authentication. We can use a combination of Route and conditional rendering to implement route guards.\n\n\nCOPY\n\nCOPY\n// PrivateRoute.js\n\nimport React from 'react';\nimport { Route, Redirect } from 'react-router-dom';\n\nconst PrivateRoute = ({ component: Component, isAuthenticated, ...rest }) => {\n  return (\n    <Route\n      {...rest}\n      render={(props) =>\n        isAuthenticated ? <Component {...props} /> : <Redirect to=\"/login\" />\n      }\n    />\n  );\n};\n\nexport default PrivateRoute;\nThis PrivateRoute component takes a component prop and an isAuthenticated prop. If the user is authenticated, it renders the specified component; otherwise, it redirects to the login page.\n\nAuthentication Workflow\nIn your application, you can implement an authentication workflow that checks the user's authentication status and controls access to protected routes.\n\n\nCOPY\n\nCOPY\n// AuthWorkflow.js\n\nimport React, { useState } from 'react';\nimport { BrowserRouter as Router, Route, Redirect } from 'react-router-dom';\nimport PrivateRoute from './PrivateRoute';\n\nconst AuthWorkflow = () => {\n  const [isLoggedIn, setLoggedIn] = useState(false);\n\n  const handleLogin = () => {\n    // Perform authentication logic\n    setLoggedIn(true);\n  };\n\n  const handleLogout = () => {\n    // Perform logout logic\n    setLoggedIn(false);\n  };\n\n  return (\n    <Router>\n      <div>\n        <Route\n          path=\"/login\"\n          render={() =>\n            isLoggedIn ? <Redirect to=\"/\" /> : <button onClick={handleLogin}>Login</button>\n          }\n        />\n        <PrivateRoute\n          path=\"/\"\n          component={() => (\n            <div>\n              <p>Welcome to the protected area!</p>\n              <button onClick={handleLogout}>Logout</button>\n            </div>\n          )}\n          isAuthenticated={isLoggedIn}\n        />\n      </div>\n    </Router>\n  );\n};\n\nexport default AuthWorkflow;\nThis example includes a login route, a private route for the protected area, and logic to handle authentication and logout actions.\n\nAdvanced Navigation Patterns\nAnimated Transitions\nReact Router allows you to implement smooth transitions between views using libraries like react-transition-group. Here's a simple example:\n\n\nCOPY\n\nCOPY\n// AnimatedTransitions.js\n\nimport React from 'react';\nimport { CSSTransition } from 'react-transition-group';\nimport { BrowserRouter as Router, Route } from 'react-router-dom';\n\nimport Home from './components/Home';\nimport About from './components/About';\nimport Contact from './components/Contact';\n\nconst AnimatedTransitions = () => {\n  return (\n    <Router>\n      <div>\n        <Route\n          path=\"/\"\n          exact\n          render={({ match }) => (\n            <CSSTransition\n              in={match != null}\n              timeout={300}\n              classNames=\"fade\"\n              unmountOnExit\n            >\n              <Home />\n            </CSSTransition>\n          )}\n        />\n        <Route\n          path=\"/about\"\n          render={({ match }) => (\n            <CSSTransition\n              in={match != null}\n              timeout={300}\n              classNames=\"fade\"\n              unmountOnExit\n            >\n              <About />\n            </CSSTransition>\n          )}\n        />\n        <Route\n          path=\"/contact\"\n          render={({ match }) => (\n            <CSSTransition\n              in={match != null}\n              timeout={300}\n              classNames=\"fade\"\n              unmountOnExit\n            >\n              <Contact />\n            </CSSTransition>\n          )}\n        />\n      </div>\n    </Router>\n  );\n};\n\nexport default AnimatedTransitions;\nIn this example, the CSSTransition component from react-transition-group is used to apply a fade-in and fade-out effect when transitioning between routes.\n\n\nBy: James Oluwaleye",
  "category": "Frontend",
  "userId": {
    "$oid": "6567e1e718cfd9fb550df1cf"
  },
  "author": {
    "name": "Admin User"
  },
  "updatedAt": null,
  "createdAt": {
    "$date": "2023-11-30T07:31:58.093Z"
  },
  "href": "mastering-navigation-with-react-router",
  "__v": 0
},
{
  "_id": {
    "$oid": "656842ddad45bdc1d2379aa0"
  },
  "title": "Advance Git & GitHub for DevOps Engineers",
  "photoUrl": "",
  "body": "Git Branching\nGit branching is a powerful feature that allows developers to diverge from the main line of development and work on isolated changes. 🌳\n\nIn Git, a branch is essentially a lightweight movable pointer to a commit. When you create a branch, you are creating a new line of development, allowing you to make changes without affecting the main codebase. 🚀\n\nBranching is particularly useful for collaborative projects and managing different features or bug fixes simultaneously. Developers can work on their features independently, and once they are ready, the changes can be merged back into the main branch. 🤝\n\nGit Revert and Reset\nGit Revert 🔄\n\nPurpose: Revert changes by creating a new commit that undoes a previous commit.\n\nUsage: git revert [commit_hash]\n\nEffect: Doesn't remove commits but adds new ones to negate the changes introduced by the specified commit.\n\nGit Reset 🔄\n\nPurpose: Reset the current branch to a specific commit, effectively discarding changes.\n\nUsage:\n\nSoft Reset: git reset --soft [commit_hash]\n\nMixed Reset (default): git reset [commit_hash]\n\nHard Reset: git reset --hard [commit_hash]\n\nEffect:\n\nSoft Reset: Moves HEAD and the branch pointer to the specified commit, keeping changes staged.\n\nMixed Reset (default): Same as soft reset but also unstages changes.\n\nHard Reset: Discards changes, both in the working directory and staging area.\n\nWhen to use:\n\nRevert: When you want to undo changes while preserving the commit history, suitable for shared branches.\n\nReset: When you want to completely discard changes and rewrite history, use with caution, especially on shared branches.\n\nBoth git revert and git reset serve different purposes, and the choice depends on whether you want to preserve the commit history or rewrite it. 📚✨\n\nGit Rebase and Merge\nGit Merge 🤝\n\nPurpose: Combine changes from different branches, integrating them into the current branch.\n\nUsage: git merge [branch_name]\n\nEffect: Creates a new commit that has two parent commits, incorporating changes from the specified branch.\n\nGit Rebase 🔄\n\nPurpose: Combine changes from one branch to another by moving or combining commits.\n\nUsage: git rebase [branch_name]\n\nEffect: Rewrites commit history by placing the changes on top of the specified branch, creating a linear history.\n\nWhen to use:\n\nMerge: When you want to maintain a clear and separate history for different features or bug fixes.\n\nRebase: When you want a clean, linear history, useful for feature branches before merging into the main branch.\n\nConsiderations:\n\nMerge: Preserves the original commit history but introduces merge commits, which can clutter the history.\n\nRebase: Provides a cleaner history but should be used with caution on shared branches, as it rewrites commit history.\n\nBoth git merge and git rebase have their advantages and use cases, and the choice depends on the project's workflow and preferences. 🚀💡\n\nTask 1:\n\nAdd a text file called version01.txt inside the Devops/Git/ with “This is first feature of our application” written inside. This should be in a branch coming from master, [hint try git checkout -b dev], swithch to dev branch ( Make sure your commit message will reflect as \"Added new feature\"). [Hint use your knowledge of creating branches and Git commit command]\n\nversion01.txt should reflect at local repo first followed by Remote repo for review. [Hint use your knowledge of Git push and git pull commands here]\nAdd new commit in dev branch after adding below mentioned content in Devops/Git/version01.txt: While writing the file make sure you write these lines\n\n1st line>> This is the bug fix in development branch\n\nCommit this with message “ Added feature2 in development branch”\n\n2nd line>> This is gadbad code\n\nCommit this with message “ Added feature3 in development branch\n\n3rd line>> This feature will gadbad everything from now.\n\nCommit with message “ Added feature4 in development branch\n\nRestore the file to a previous version where the content should be “This is the bug fix in development branch” [Hint use git revert or reset according to your knowledge]\n\nSolution :\n\nCertainly! Here's a step-by-step guide to achieve the described scenario:\n\nStep 1: Create and Switch to Dev Branch\n\nCOPY\n\nCOPY\n# Create and switch to the dev branch\ngit checkout -b dev\nStep 2: Add version01.txt\n\nCOPY\n\nCOPY\n# Create version01.txt with the specified content\necho \"This is the first feature of our application\" > Devops/Git/version01.txt\n\n# Add the file to the staging area\ngit add Devops/Git/version01.txt\n\n# Commit with the message \"Added new feature\"\ngit commit -m \"Added new feature\"\nStep 3: Push to Remote Repository\n\nCOPY\n\nCOPY\n# Push the changes to the remote repository\ngit push -u origin dev\nStep 4: Add New Commits to Dev Branch\n\nCOPY\n\nCOPY\n# Open version01.txt and add the specified content\necho \"This is the bug fix in development branch\" >> Devops/Git/version01.txt\ngit add Devops/Git/version01.txt\ngit commit -m \"Added feature2 in development branch\"\n\necho \"This is gadbad code\" >> Devops/Git/version01.txt\ngit add Devops/Git/version01.txt\ngit commit -m \"Added feature3 in development branch\"\n\necho \"This feature will gadbad everything from now.\" >> Devops/Git/version01.txt\ngit add Devops/Git/version01.txt\ngit commit -m \"Added feature4 in development branch\"\nStep 5: Restore the File to a Previous Version\nOption 1: Using Git Revert\n\n\nCOPY\n\nCOPY\n# Revert the last commit, effectively restoring the file to a previous version\ngit revert HEAD\nOption 2: Using Git Reset (Use with caution, as it rewrites history)\n\n\nCOPY\n\nCOPY\n# Reset to the commit before the last one\ngit reset --hard HEAD~1\nImportant Notes:\nAlways be cautious when using git reset --hard as it can rewrite history, which may lead to data loss.\n\nIf the branch is already pushed to the remote repository, force push (git push -f) might be necessary after a reset to update the remote branch. However, be careful with force pushing on shared branches to avoid conflicts.",
  "category": "Cloud",
  "userId": {
    "$oid": "6567e1e718cfd9fb550df1cf"
  },
  "author": {
    "name": "Admin User"
  },
  "updatedAt": null,
  "createdAt": {
    "$date": "2023-11-30T08:07:57.512Z"
  },
  "href": "advance-git-and-github-for-devops-engineers",
  "__v": 0
},
{
  "_id": {
    "$oid": "656eca1fbbe1dec30053b604"
  },
  "title": "Learn How to Install & Implement Tailwind CSS on Next.js",
  "photoUrl": "https://cdn.hashnode.com/res/hashnode/image/upload/v1674283280364/0c0296ca-0b8c-4d39-9209-cf8f0ea52892.png?auto=compress,format&format=webp",
  "body": "Introduction\nTailwind CSS is a utility-first framework popular among front-end developers with over 64 thousand stars on GitHub and over 4.6 million downloads on NPM. It provides the ability to build highly scalable and customizable components with zero to few CSS.\n\nThis article will guide you on how to add Tailwind CSS to a Next.js project. The guide can also be used to set up Tailwind CSS on fresh or existing Next.js projects.\n\nWhat is Next.js?\nNext.js is one of the leading JavaScript frameworks built on top of React.js by the creator of Vercel. It offers functionalities such as Server Side Rendering (SSR), Static Site Generation (SSG), image optimization, fast refresh, and more.\nhe combination of Next.js and Tailwind CSS will enable you to build a performant, modern, easy-to-maintain, and scalable full-stack project.\n\nIn the next sections, we'll take a look at various methods of how to set up a Next.js project with Tailwind CSS.\n\nSetting Up Next.js and Tailwind CSS using the with-tailwind-css Template\nThe easiest way to set up a Next.js project with Tailwind CSS configuration is by using the official Next js Tailwind CSS example template named with-tailwind-css.\n\nThis is a public repository on GitHub, maintained by the Next.js team, and can be used as a starter kit for a new Next.js project. The advantage of using this method is that it's fast and error-free, and it follows the best practices of setting up Tailwind CSS in Next.js.\n\nRun the command below to setup a new Next.js project using the with-tailwind-css template:\n\n\nCOPY\n\nCOPY\nnpx create-next-app --example with-tailwindcss my-app-with-tailwind\nThe command above will install a new Next.js app named my-app-with-tailwind with Tailwind CSS already installed.",
  "category": "Frontend",
  "userId": {
    "$oid": "6567e1e718cfd9fb550df1cf"
  },
  "author": {
    "name": "Admin User"
  },
  "updatedAt": null,
  "createdAt": {
    "$date": "2023-12-05T06:58:39.487Z"
  },
  "href": "learn-how-to-install-and-implement-tailwind-css-on-next.js",
  "__v": 0
},
{
  "_id": {
    "$oid": "656ed2aebbe1dec30053b608"
  },
  "title": "Introduction to Pandas 🐼",
  "photoUrl": "https://cdn.hashnode.com/res/hashnode/image/upload/v1701490244771/d0ae5010-1bda-45a5-806a-969167c17a35.gif?w=1600&h=840&fit=crop&crop=entropy&auto=format,compress&gif-q=60&format=webm",
  "body": "Introduction\nPandas is a powerful and widely used open-source data manipulation and analysis library for Python. It provides data structures like DataFrame and Series, making it easy to work with structured data. Whether you're dealing with cleaning, analyzing, or visualizing data, Pandas is an indispensable tool in the data science and analytics toolbox.\n\nWhat is Pandas?\nAt its core, Pandas is designed to handle two main types of data structures:\n\nDataFrame: A two-dimensional, tabular data structure with labeled axes (rows and columns). It's similar to a spreadsheet or SQL table.\n\nSeries: A one-dimensional labeled array, which can hold any data type.\n\nPandas excels at handling real-world data, supporting operations such as merging, reshaping, slicing, indexing, and aggregating data effortlessly.\n\nInstalling Pandas 🛠️\nBefore diving into the world of Pandas, you need to install it. The recommended way is to use the Python package manager, pip. Open your terminal or command prompt and type the following command:\n\n\nCOPY\n\nCOPY\npip install pandas\nThis command will download and install the latest version of Pandas and its dependencies.\n\nImporting Pandas 📦\nOnce installed, you can import Pandas in your Python script or Jupyter notebook. Conventionally, it's imported with the alias pd:\n\n\nCOPY\n\nCOPY\nimport pandas as pd\nNow that you have Pandas installed and ready to go, let's explore why it's an essential tool in the data science and analysis domain.\n\nWhy Use Pandas? 🤔\nUse Case 1: Data Cleaning and Preprocessing 🧹\nProblem:\nYou have a dataset with missing values, duplicates, and inconsistent formatting.\n\nSolution:\nPandas provides functions to handle missing data (dropna, fillna), remove duplicates (drop_duplicates), and standardize data formats (str.replace, str.lower).\n\n\nCOPY\n\nCOPY\n# Example\nimport pandas as pd\n\n# Load your dataset\ndf = pd.read_csv('your_dataset.csv')\n\n# Handle missing values\ndf.dropna(inplace=True)\n\n# Remove duplicates\ndf.drop_duplicates(inplace=True)\n\n# Standardize text data\ndf['column_name'] = df['column_name'].str.lower()\nUse Case 2: Data Analysis and Exploration 📊\nProblem:\nYou need to explore and analyze the key insights from your dataset.\n\nSolution:\nPandas simplifies data analysis with functions like groupby, describe, and value_counts.\n\n\nCOPY\n\nCOPY\n# Example\nimport pandas as pd\n\n# Load your dataset\ndf = pd.read_csv('your_dataset.csv')\n\n# Group data by a column\ngrouped_data = df.groupby('category_column')['numeric_column'].mean()\n\n# Descriptive statistics\nsummary_stats = df.describe()\n\n# Value counts\ncategory_counts = df['category_column'].value_counts()\nUse Case 3: Data Visualization 📈\nProblem:\nYou want to create informative visualizations based on your data.\n\nSolution:\nPandas integrates seamlessly with popular data visualization libraries like Matplotlib and Seaborn.\n\n\nCOPY\n\nCOPY\n# Example\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Load your dataset\ndf = pd.read_csv('your_dataset.csv')\n\n# Plot a bar chart\ndf['category_column'].value_counts().plot(kind='bar')\nplt.title('Distribution of Categories')\nplt.xlabel('Categories')\nplt.ylabel('Count')\nplt.show()\nPandas' versatility and ease of use make it an invaluable tool for a wide range of data-related tasks. Now that you understand the basics, start exploring the endless possibilities that Pandas offers! 🚀 - BY Prasad Suman Mohan",
  "category": "Data Science",
  "userId": {
    "$oid": "6567e1e718cfd9fb550df1cf"
  },
  "author": {
    "name": "Admin User"
  },
  "updatedAt": null,
  "createdAt": {
    "$date": "2023-12-05T07:35:10.207Z"
  },
  "href": "introduction-to-pandas",
  "__v": 0
},
{
  "_id": {
    "$oid": "656ed511bbe1dec30053b6c7"
  },
  "title": "Understanding Bubble Sort - Sorting Algorithm.",
  "photoUrl": "https://cdn.hashnode.com/res/hashnode/image/upload/v1701514773489/ca2acba9-6d10-43d7-8aa7-bfd37fa1248e.jpeg?w=1600&h=840&fit=crop&crop=entropy&auto=compress,format&format=webp",
  "body": "Introduction\nIn this world, in our day to day life, we deal with data, and these data comes in form of numbers and words. These data can be ordered or unordered, and sometimes there is a need to make these data be in an orderly manner(ascending or descending order).\n\nIn computer science, there are several ways/methods that provides systematic way of organizing these data or information. These ways are all referred to as Sorting Algorithms, and there are quite a number of them, which we will be discussing in this series.\n\nFor a start, we will be exploring one of the most straight forward and easiest one, which is the Bubble Sort Algorithm This algorithm is used to order data in a linear data structure (Linked lists, arrays etc.) either in an ascending or descending order depending on the need.\n\nBubble Sorting Algorithm\nBefore we look at examples on how to use bubble sort to organize and arrange data in an orderly manner. Let us take out time to understand how the Bubble Sort Algorithm works.\n\nBubble Sort Algorithm sorts data by comparing adjacent elements of a data set, and based on this comparison it either swaps the elements based on the fact that for ascending order, the larger elements shifts to the right, and the smaller elements to the left, so at the end, we have the largest element at the far most right and the smallest element at the far most left, with the other elements in-between from the right, the larger ones down to the left, the smaller ones.\n\nBelow is an illustration of how this works:\n\nFor Bubble Sort to work, we need to have several Passes, and for each Pass, we need to have several Checks. So let us say we are considering an array with about 5 elements, that means we need to have about 4 Passes and under each passes, we can also have 4 checks. Note: The number of Passes and checks required is always a number less than the number of elements in our data. Reason being that if we have let's say 5 elements in our data, by arranging 4 of those data in the correct location, it automatically sets the 5th data in it's correct location, so there wouldn't be a need to arrange that one. So for any n number of elements in our data, the number of Passes will be n - 1 and the number of checks will also be n - 1.\n\nSo considering the array { 13, 15, 9, 10, 8 }. Here we can see that the number of elements are 5, and so the number of Passes will definitely be 4, likewise the number of checks will be 4 also. Let us now see this concept in action:\n\nPass 1\nFor the first pass, in arranging the array stated above: { 13, 15, 9, 10, 8 }, we will check each of the elements by comparing the ones that are adjacent to each other. And the basis of our comparison will be which one is greater and which one is less than. The one that is greater will always be moved to the right, while the one that is lesser will always be moved to the left, in this case, we will be swapping their positions to meet this requirement, where the requirement isn't already met.\nSo starting, we will start with the first two elements, which in this case is the 13 and 15. We will compare the two elements to see which is the greater, and lesser, here you can see that the greater element is already in the correct position, which is by the right and the lesser element is already in the correct position too, which is by the left, thus, no swapping is done, we simply return back the array. By: Gideon Bature",
  "category": "Programming Language",
  "userId": {
    "$oid": "6567e1e718cfd9fb550df1cf"
  },
  "author": {
    "name": "Admin User"
  },
  "updatedAt": null,
  "createdAt": {
    "$date": "2023-12-05T07:45:21.155Z"
  },
  "href": "understanding-bubble-sort-sorting-algorithm.",
  "__v": 0
},
{
  "_id": {
    "$oid": "656ed589bbe1dec30053b6cb"
  },
  "title": "Is Node.js Dying ? Trend Analysis of Node.js in 2023",
  "photoUrl": "https://cdn.hashnode.com/res/hashnode/image/upload/v1701464690516/6d329ce2-b425-4cfb-bdde-caf7463a211d.png?w=1600&h=840&fit=crop&crop=entropy&auto=compress,format&format=webp",
  "body": "Introduction\nIn the ever-evolving landscape of web development, Node.js has established itself as an unassailable powerhouse. As we enter 2023, it's still a major player, known for being fast, scalable, and flexible – a key element in modern web applications. Let's delve into its trends to find out is node.js really dying.\n\nThe Backbone of Node.js's Popularity\nIn 2023, Node.js remains incredibly popular, thanks to its outstanding features. Its winning combination of speed, scalability, and versatility doesn't just make it a player; it's a game-changer in web development. Developers love it for its features that make handling modern application development a breeze.\n\nRiding the JavaScript Wave\nNode.js stays on top in 2023 because it syncs seamlessly with the widespread use of JavaScript in web development. It makes things simpler by letting developers use one language for both frontend and backend, reducing the learning curve. The \"JavaScript Everywhere\" approach continues to be a strong reason behind Node.js's lasting popularity.\n\nNode.js Popularity in 2023: Numbers & Trends\nI know numbers are boring, but somehow going through them, we can paint a picture of Node.js popularity in tech market. So, let's delve deeper with concrete data from surveys and downloads. You can click the hyperlinks, to read more on it.\n\n1. Developer Surveys:\n\nStack Overflow Developer Survey 2023: Node.js holds the top position among most wanted technologies, desired by 33.55% of respondents.\n\nState of JavaScript 2023: A whopping 82.3% of developers reported using Node.js in the past year.\n\nGodel Technologies 2023 JavaScript Trends: Node.js is the most used backend framework, utilized by 42% of respondents\n\n2. Download Statistics:\n\nNPM Downloads: According to npmJS, Node.js downloads have exceeded 2.7 billion monthly downloads.\n\nNodeJS.org Downloads: The official Node.js website reports over 1.7 billion downloads as of October 2023.\n\n3. Job Market Trends:\n\nIndeed: Node.js developer jobs grew by 57% year-over-year in 2022, highlighting its increasing demand.\n\nDice.com: Node.js developer salaries continue to be above the average for software developers.\n\n4. Community Engagement:\n\nGitHub: The Node.js repository boasts over 74,000 stars and 21,000 forks, demonstrating active community engagement.\n\nStack Overflow: The Node.js tag on Stack Overflow receives over 100,000 questions per year, indicating a vibrant community seeking and providing support.\n\n5. Market Share:\n\nW3Techs: Node.js powers 54.7% of websites worldwide with a server-side JavaScript language, solidifying its market dominance.\n\nNetCraft: Node.js holds a 1.67% market share among all websites, demonstrating its widespread usage.\n\nThe combination of survey data, download statistics, job market trends, community engagement, and market share paints a clear picture of Node.js's immense popularity in 2023. Its versatility, performance, and growing ecosystem position it as a leading technology for web development and beyond.\n\nTrends Steering Node.js in 2023\nA Numeric Preview Breaking down the specific trends shaping Node.js in 2023 provides a numeric preview of its trajectory.\n\nGraphQL: This data query language is gaining momentum for building APIs, seamlessly integrating with Node.js to create flexible and efficient solutions\n\nMicroservices Architecture: Node.js's modularity and scalability make it a preferred choice for building microservices-based applications, aligning with the prevailing architecture trends\n\nServerless Computing: As serverless platforms like AWS Lambda and Google Cloud Functions gain ground, Node.js stands as an easily integrable tool for constructing serverless applications\n\nEdge Computing: Node.js's lightweight footprint and real-time data processing capabilities position it as an optimal choice for edge computing scenarios, where data processing occurs closer to the source\n\nAI and ML Integration: The flexibility of Node.js provides a robust platform for seamlessly integrating AI and ML models into web applications, empowering developers to build intelligent and interactive solutions\n\nThe Ever-Relevant Node.js\nThe stuff you might already know, so feel free to skip this. But, if you are newbie learning Node.js just give it a read.\n\nUnpacking the Advantages In a tech landscape where relevance is fleeting, Node.js not only maintains its standing but solidifies its indispensability in 2023.\n\nEase of Use: Node.js is celebrated for its simple and intuitive API, ensuring ease of learning and use, even for developers with limited JavaScript experience\n\nPerformance: Built for speed and efficiency, Node.js guarantees that applications can handle high traffic and demanding workloads, with a benchmarked speed increase of 25% in 2023\n\nScalability: Node.js effortlessly scales to meet the demands of growing applications, affirming its suitability for projects of all sizes\n\nVersatility (Application Types Supported: Websites, Web Services, Mobile Apps, Desktop Applications): Node.js can be employed to build a myriad of applications, showcasing its versatility across websites, web services, mobile apps, and even desktop applications\n\nVibrant Community (Community Engagement Metrics: 4 Million Active Contributors): The Node.js community, with its four million active contributors, stands as a dynamic support system, offering extensive resources and assistance for developers of all proficiency levels\n\nConclusion\nAs we wrap up our look into Node.js in 2023, one thing is clear – it's not just a tech; it's a powerhouse in web development. With a strong history of being fast, scalable, and versatile, Node.js is set to be a crucial part of modern applications.\n\nIn the ever-changing world of web development, Node.js isn't just an option; it's a key advantage, making sure developers stay on the cutting edge of innovation.\n\nThe above metric, gives us a sigh of relief, that Node.js is still popular in the tech market and its demand is skyrocketing.\n\nIf you like my work, subscribe to my newsletter to never miss an update. Also, do support me by liking, commenting and sharing the article. These small things, keep me motivated to contribute such content 😌.\nBy: Masood Akhtar Vaheed",
  "category": "Backend",
  "userId": {
    "$oid": "6567e1e718cfd9fb550df1cf"
  },
  "author": {
    "name": "Admin User"
  },
  "updatedAt": null,
  "createdAt": {
    "$date": "2023-12-05T07:47:21.265Z"
  },
  "href": "is-node.js-dying-trend-analysis-of-node.js-in-2023",
  "__v": 0
},
{
  "_id": {
    "$oid": "656ed810bbe1dec30053b6cf"
  },
  "title": "JavaScript fundamentals before learning React",
  "photoUrl": "",
  "body": "After all my teachings about React, be it online for a larger audience or on-site for companies transitioning to web development and React, I always come to the conclusion that React is all about JavaScript. Newcomers to React but also myself see it as an advantage, because you carry your JavaScript knowledge for a longer time around compared to your React skills.\n\nDuring my workshops, the larger part of the material is about JavaScript and not React. Most of it boils down to JavaScript ES6 and beyond — features and syntax — but also ternary operators, shorthand versions in the language, the this object, JavaScript built-in functions (map, reduce, filter) or more general concepts such as composability, reusability, immutability, closures, truth tables, or higher-order functions. These are the fundamentals, which you don't need necessarily to master before starting with React, but which will definitely come up while learning or practicing it.\n\nThe following walkthrough is my attempt giving you an almost extensive yet concise list about all the different JavaScript functionalities that complement your React knowledge. If you have any other things which are not in the list, just leave a comment for this article and I will keep it up to date.\n\nENTERING REACT AFTER LEARNING JAVASCRIPT\nWhen you enter the world of React, you are often confronted with a React Class Component:\n\n\nCOPY\n\nCOPY\nimport React, { Component } from 'react';\nimport logo from './logo.svg';\nimport './App.css';\n\nclass App extends Component {\n  render() {\n    return (\n      <div className=\"App\">\n        <header className=\"App-header\">\n          <img src={logo} className=\"App-logo\" alt=\"logo\" />\n          <h1>\n            Hello React\n          </h1>\n          <a href=\"https://reactjs.org\">\n            Learn React\n          </a>\n        </header>\n      </div>\n    );\n  }\n}\n\nexport default App;\nIn a React class component, there are lots of things to digest for beginners which are not necessarily React: class statements, class methods and inheritance due to being a class. Also JavaScript import statements are only adding complexity when learning React. Even though the main focus point should be JSX (React’s syntax) — everything in the return statement — in the very beginning, often all the things around demand explanations as well. This article is supposed to shed some light into all the things around, most of it JavaScript, without worrying too much about React.\n\nREACT AND JAVASCRIPT CLASSES\nReact\n\nBeing confronted with a React class component, requires the prior knowledge about JavaScript classes. One would assume that this is given knowledge, but it isn’t, because JavaScript classes are fairly new in the language. Previously, there was only JavaScript’s prototype chain which has been used for inheritance too. JavaScript classes build up on top of the prototypical inheritance giving the whole thing a simpler representation with syntactic sugar.\n\nIn order to understand JavaScript classes, you can take some time learning about them without React:\n\n\nCOPY\n\nCOPY\nclass Developer {\n  constructor(firstname, lastname) {\n    this.firstname = firstname;\n    this.lastname = lastname;\n  }\n\n  getName() {\n    return this.firstname + ' ' + this.lastname;\n  }\n}\n\nvar me = new Developer('Robin', 'Wieruch');\n\nconsole.log(me.getName());\nA class describes an entity which is used as a blueprint to create an instance of this entity. Once an instance of the class gets created with the new statement, the constructor of the class is called which instantiates the instance of the class. Therefore, a class can have properties which are usually located in its constructor. In addition, class methods (e.g. getName()) are used to read (or write) data of the instance. The instance of the class is represented as the this object within the class, but outside the instance is just assigned to a JavaScript variable.\n\nUsually classes are used for inheritance in object-oriented programming. They are used for the same in JavaScript whereas the extends statement can be used to inherit with one class from another class. The more specialized class inherits all the abilities from the more general class with the extends statement, and can add its specialized abilities to it:\n\n\nCOPY\n\nCOPY\nclass Developer {\n  constructor(firstname, lastname) {\n    this.firstname = firstname;\n    this.lastname = lastname;\n  }\n\n  getName() {\n    return this.firstname + ' ' + this.lastname;\n  }\n}\n\nclass ReactDeveloper extends Developer {\n  getJob() {\n    return 'React Developer';\n  }\n}\n\nvar me = new ReactDeveloper('Robin', 'Wieruch');\n\nconsole.log(me.getName());\nconsole.log(me.getJob());\nBasically that’s all it needs to fully understand React class components. A JavaScript class is used for defining a React component, but as you can see, the React component is only a “React component” because it inherits all the abilities from the actual React Component class which is imported from the React package:\n\n\nCOPY\n\nCOPY\nimport React, { Component } from 'react';\n\nclass App extends Component {\n  render() {\n    return (\n      <div>\n        <h1>Welcome to React</h1>\n      </div>\n    );\n  }\n}\n\nexport default App;\nThat’s why the render() method is mandatory in React class components: The React Component from the imported React package instructs you to use it for displaying something in the browser. Furthermore, without extending from the React Component, you wouldn't be able to use other lifecycle methods. For instance, there wouldn't be a componentDidMount() lifecycle method, because the component would be an instance of a vanilla JavaScript class. And not only the lifecycle methods would go away, React's API methods such as this.setState() for local state management wouldn't be available as well.\n\nHowever, as you have seen, using a JavaScript class is beneficial for extending the general class with your specialized behavior. Thus you can introduce your own class methods or properties.\n\n\nCOPY\n\nCOPY\nimport React, { Component } from 'react';\n\nclass App extends Component {\n  getGreeting() {\n    return 'Welcome to React';\n  }\n\n  render() {\n    return (\n      <div>\n        <h1>{this.getGreeting()}</h1>\n      </div>\n    );\n  }\n}\n\nexport default App;\nNow you know why React uses JavaScript classes for defining React class components. They are used when you need access to React’s API (lifecycle methods, this.state and this.setState()). In the following, you will see how React components can be defined in a different way without using a JavaScript class.\n\nAfter all, JavaScript classes welcome one using inheritance in React, which isn’t a desired outcome for React, because React favors composition over inheritance. So the only class you should extend from your React components should be the official React Component.\n\n",
  "category": "Frontend",
  "userId": {
    "$oid": "6567e1e718cfd9fb550df1cf"
  },
  "author": {
    "name": "Admin User"
  },
  "updatedAt": null,
  "createdAt": {
    "$date": "2023-12-05T07:58:08.371Z"
  },
  "href": "javascript-fundamentals-before-learning-react",
  "__v": 0
},
{
  "_id": {
    "$oid": "656ed87ebbe1dec30053b6d3"
  },
  "title": "I Predicted the Future With MindsDB",
  "photoUrl": "https://cdn.hashnode.com/res/hashnode/image/upload/v1699569441589/c48f7ed4-41a0-4534-8824-2de75181a29a.png?w=1600&h=840&fit=crop&crop=entropy&auto=compress,format&format=webp",
  "body": "One of the amazing features on MindsDB is that you have access to tens of data sources that help you access datasets from other platforms. One of the handlers that I worked on is the PyPI Handler. It uses PyPI's databases as a data source.\n\nIn this article, we'll be using this handler to make a prediction over the future download rate of a Python package. Keep in mind that this method uses time-series training strategies and the output is from a linear regression model meaning the output is not quite accurate.\n\nTo make this process faster, I'm going to start up a local MindsDB instance and train my model locally. At the end of this tutorial, you'll have access to the Notebook files.\n\nIn this tutorial, we need..\n\nA local instance of MindsDB\n\nJupiter Notebook (optional)\n\nSetting Up\nAs I said, we need a local MindsDB instance. You can either run up a Docker container or do it in a traditional way using a venv and install the requirements inside the environment.\n\nFollow this official tutorial to run a local MindsDB instance.\n\nMake sure your MindsDB engine is up and running and navigate to http://localhost:47334/. You should see the dashboard.\n\n\n\nTrain Your Model\nNow, we have to train a model before we jump into any further steps. To do so, you have to execute the following SQL code.\n\n\nCOPY\n\nCOPY\nCREATE DATABASE pypi_datasource\nWITH ENGINE = 'pypi';\n\nCREATE MODEL mindsdb.pypi_model\nFROM pypi_datasource\n  (SELECT *\nFROM pypi_datasource.overall WHERE package=\"<PACKAGE-NAME>\" AND mirrors=true limit 500)\nPREDICT downloads;\nIt creates a PyPI table and prepares a model based on the following SQL sequence.\n\n\nCOPY\n\nCOPY\nSELECT *\nFROM pypi_datasource.overall WHERE package=\"<PACKAGE-NAME>\" AND mirrors=true limit 500)\nPREDICT downloads;\nYou can refer to this document for more options and parameters if you need to modify your sequence.\n\nI'm trying to predict the download rate of the requests library. It's a famous one so let's see how is our model going to do.\n\n\n\nAs you can see, my model's status is \"generating\" meaning my model is not yet ready. Once it's fully prepared and ready to be prompted, you'll see a check mark on the bottom-left part of your dashboard that says your \"pypi_model\" is ready to be used.\n\nPredict\nTo do the prediction, I need a bunch of fancy tools to make an epic scene from my prediction. For that manner, I'm using Plotly which is a plotting library in Python. You can use any other tool that you need. To connect to the local MindsDB, I'm using mindsdb_sdk.\n\nBefore I jump into the connection phase, I need to set some variables.\n\n\nCOPY\n\nCOPY\n# variables\nDAYS_TO_BE_PREDICTED = 100\nMINDSDB_INSTANCE = \"http://127.0.0.1:47334\"\nPACKAGE_NAME = \"requests\"\nMake sure to modify DAYS_TO_BE_PREDICTED and PACKAGE_NAME variables based on your needs.\n\n\nCOPY\n\nCOPY\nfrom datetime import datetime, timedelta\n\nimport mindsdb_sdk\n\n# variables\n# ...\n\nserver = mindsdb_sdk.connect()\nserver = mindsdb_sdk.connect(MINDSDB_INSTANCE)\n\ndatabases = server.list_databases()\ndatabase = databases[-1]\nLet's take a batch from the download rate data to sort our model for prediction.\n\n\nCOPY\n\nCOPY\nquery = database.query(\n    f'SELECT date, downloads FROM pypi_datasource.overall WHERE package=\"{PACKAGE_NAME}\" AND mirrors=true limit 500'\n)\noverall_df = query.fetch()\nNow, let's take our prediction data based on overall_df.\n\n\nCOPY\n\nCOPY\n# an empty dataframe\npredicted_df = pd.DataFrame(columns=[\"date\", \"downloads\"])\n\ntoday = datetime.today()\ncurrent_date = (today - timedelta(days=180)).date()\n\nfor i in range(DAYS_TO_BE_PREDICTED):\n    query = database.query(\n        f'SELECT date, downloads FROM mindsdb.pypi_model WHERE date=\"{current_date}\"'\n    )\n    predicted_value = query.fetch()\n    current_date = (today + timedelta(days=i)).date()\n    predicted_df = pd.concat([predicted_df, query.fetch()], ignore_index=True)\nRight after the for-loop, our predicted_df is filled with the predicted download rates on each day. This is a quick showcase on how this variable looks like.\n\n\n\nAs I said, I'll use Plotly to make a plot view from this data and the real values.\n\n\nCOPY\n\nCOPY\nimport pandas as pd\nimport plotly.graph_objects as go\n\n# ...\n\nfig = go.Figure()\n\nfig.add_trace(\n    go.Scatter(\n        x=overall_df[\"date\"], y=overall_df[\"downloads\"], mode=\"lines\", name=\"Data\"\n    )\n)\nfig.add_trace(\n    go.Scatter(\n        x=predicted_df[\"date\"],\n        y=predicted_df[\"downloads\"],\n        mode=\"lines\",\n        name=\"Prediction\",\n    )\n)\nfig.update_layout(\n    title=\"PyPI Package Download Rate Prediction\",\n    xaxis_title=\"Dates\",\n    yaxis_title=\"Downloads\",\n    template=\"plotly_dark\",\n)\n\nfig.show()\n",
  "category": "Data Science",
  "userId": {
    "$oid": "6567e1e718cfd9fb550df1cf"
  },
  "author": {
    "name": "Admin User"
  },
  "updatedAt": null,
  "createdAt": {
    "$date": "2023-12-05T07:59:58.070Z"
  },
  "href": "i-predicted-the-future-with-mindsdb",
  "__v": 0
},
{
  "_id": {
    "$oid": "656ed973bbe1dec30053b6d7"
  },
  "title": "Deploying a Single Page Application (SPA) on AWS: A Beginner's Guide. Part 7. AWS App Runner",
  "photoUrl": "https://cdn.hashnode.com/res/hashnode/image/upload/v1697641396658/d3cf9a3e-c0ff-460f-a40d-eb4058f61b52.png?w=1600&h=840&fit=crop&crop=entropy&auto=compress,format&format=webp",
  "body": "Introduction\nIn this part of the series, the focus is on running your backend application in a production environment. The goal is to provide the necessary tooling to fulfil the Observable, Seamlessly Updatable, and Failure-Tolerant criteria of a Cloud-Ready App, as described in the FROSST criteria from the Cloud Strategy - A Decision-based Approach to Successful Cloud Migration - The Architect Elevator Book.\n\nBefore CloudFormation (CFN) Template\nBefore diving into the CloudFormation template, it's essential to set up observability. This can be done by creating an observability configuration using the AWS CLI:\n\n\nCOPY\n\nCOPY\naws apprunner create-observability-configuration --observability-configuration-name rest-api --trace-configuration Vendor=AWSXRAY\nAfter creating the configuration, retrieve the ARN from the ObservabilityConfigurationArn field in the output, as shown in the JSON snippet:\n\n\nCOPY\n\nCOPY\n{\n    \"ObservabilityConfiguration\": {\n        \"ObservabilityConfigurationArn\": \"arn:aws:apprunner:eu-central-1:1111111111:observabilityconfiguration/rest-api/1/xxxxxx\",\n        \"ObservabilityConfigurationName\": \"rest-api\",\n        \"TraceConfiguration\": {\n            \"Vendor\": \"AWSXRAY\"\n        },\n        \"ObservabilityConfigurationRevision\": 1,\n        \"Latest\": true,\n        \"Status\": \"ACTIVE\",\n        \"CreatedAt\": \"2023-10-12T19:11:23.425000+02:00\"\n    }\n}\nApp Runner CloudFormation (CFN) Template to Support Failure Tolerance\nLet's dive into the CloudFormation template:\n\n\nCOPY\n\nCOPY\nAWSTemplateFormatVersion: '2010-09-09'\nDescription: Backend deployed viaAWS App Runner\nParameters:\n  Environment:\n    Type: String\n    Default: production\n    Description: A name for the environment that this cloudformation will be part of.\n                 Used to locate other resources in the same environment.\n  ImageUrl:\n    Type: String\n    Description: The url of a docker image that contains the application process that\n                 will handle the traffic for this service. Should be on ECR private\n  ObservabilityConfigurationArnParam:\n    Type: String\n    Description: Create it via aws cli  aws apprunner create-observability-configuration --observability-configuration-name rest-api --trace-configuration Vendor=AWSXRAY\n\nResources: \n  # Backend\n  AppRunnerRole:\n    Type: AWS::IAM::Role\n    Properties:\n      AssumeRolePolicyDocument:\n        Version: '2008-10-17'\n        Statement:\n          - Effect: Allow\n            Principal:\n              Service:\n                - build.apprunner.amazonaws.com\n            Action: sts:AssumeRole\n      ManagedPolicyArns:\n        - arn:aws:iam::aws:policy/service-role/AWSAppRunnerServicePolicyForECRAccess\n\n  Backend:\n    Type: AWS::AppRunner::Service\n    Properties:\n      ServiceName: !Sub ${AWS::StackName}-restapi-${Environment}\n      ObservabilityConfiguration:\n        ObservabilityEnabled: true\n        ObservabilityConfigurationArn: !Ref ObservabilityConfigurationArnParam\n      InstanceConfiguration:\n        Cpu: 0.25 vCPU\n        Memory: 0.5 GB\n      SourceConfiguration:\n        AuthenticationConfiguration:\n          AccessRoleArn: !GetAtt AppRunnerRole.Arn\n        ImageRepository:\n          ImageRepositoryType: ECR\n          ImageIdentifier: !Ref ImageUrl\n          ImageConfiguration:\n            Port: 8080\n      HealthCheckConfiguration:\n          HealthyThreshold: 1\n          Interval: 10\n          Path: /api/greeting\n          Protocol: HTTP\n          Timeout: 5\n          UnhealthyThreshold: 5\n      Tags:\n        - Key: environment\n          Value: !Ref Environment\n\n  # Api Gateway\n  ApiGatewayRestApi:\n    Type: AWS::ApiGateway::RestApi\n    Properties:\n      Name: !Sub ${AWS::StackName}-gateway-${Environment}\n  ApiGatewayResource:\n    Type: AWS::ApiGateway::Resource\n    Properties:\n      ParentId:\n        !GetAtt ApiGatewayRestApi.RootResourceId\n      PathPart: '{proxy+}'\n      RestApiId:\n        !Ref ApiGatewayRestApi\n  ApiGatewayMethod:\n    Type: AWS::ApiGateway::Method\n    Properties:\n      HttpMethod: ANY\n      ResourceId:\n        !Ref ApiGatewayResource\n      RestApiId:\n        !Ref ApiGatewayRestApi\n      AuthorizationType: NONE\n      RequestParameters:\n        method.request.path.proxy: true\n      Integration:\n        RequestParameters:\n          integration.request.path.proxy: method.request.path.proxy\n        Type: HTTP_PROXY\n        IntegrationHttpMethod: ANY\n        Uri: !Sub \"https://${Backend.ServiceUrl}/{proxy}\"\n  ApiGatewayDeployment:\n    Type: 'AWS::ApiGateway::Deployment'\n    DependsOn:\n      - ApiGatewayMethod\n    Properties:\n      RestApiId:\n        !Ref ApiGatewayRestApi\n      StageName: !Ref Environment\n\nOutputs:\n  AppRunnerServiceArn:\n    Description: AppRunnerServiceArn\n    Value: !GetAtt Backend.ServiceArn\n  AppRunnerServiceId:\n    Description: AppRunnerServiceId\n    Value: !GetAtt Backend.ServiceId\n  AppRunnerServiceUrl:\n    Description: AppRunnerServiceUrl\n    Value: !GetAtt Backend.ServiceUrl\n  IntegrationAPI:\n    Description: URL For CDN\n    Value: !Sub \"https://${ApiGatewayRestApi}.execute-api.${AWS::Region}.amazonaws.com/${Environment}\"\nThis AWS CloudFormation template defines the infrastructure for deploying a backend application using AWS App Runner and exposing it via AWS API Gateway. Let's break down its key components:\n\nParameters\nEnvironment: Specifies the name of the environment (e.g., production or development) that this CloudFormation stack is part of.\n\nImageUrl: The URL of a Docker image containing the application process to handle traffic. This image should be stored in a private Amazon ECR registry.\n\nObservabilityConfigurationArnParam: ARN for the observability configuration, which can be created using the AWS CLI.\n\nResources\nAppRunnerRole (IAM Role): This role allows the App Runner service to assume it and interact with other AWS services. It also attaches the necessary managed policy to access ECR.\n\nBackend (AWS App Runner Service): Defines the App Runner service, specifying its name, observability configuration, instance configuration (CPU and memory), source configuration (image repository details), health check configuration, and tags.\n\nApiGatewayRestApi (API Gateway REST API): Creates the entry point for the API Gateway.\n\nApiGatewayResource (API Gateway Resource): Configures a wildcard proxy resource to forward all requests to the App Runner service.\n\nApiGatewayMethod (API Gateway Method): Defines a method that allows any HTTP method and integrates with the backend via HTTP_PROXY.\n\nApiGatewayDeployment (API Gateway Deployment): Deploys the API Gateway to a specified stage, making it accessible externally.\n\nOutputs\nAppRunnerServiceArn: The ARN of the App Runner service.\n\nAppRunnerServiceId: The ID of the App Runner service.\n\nAppRunnerServiceUrl: The URL of the App Runner service.\n\nIntegrationAPI: The external URL for accessing the API through the API Gateway.\n\nThis template sets up a backend service using AWS App Runner, utilizing a Docker image from ECR, and configures an API Gateway to handle and forward HTTP requests to this backend. It also supports observability through AWS X-Ray and offers outputs for accessing both the backend service and the API Gateway endpoint. Parameterizing the environment allows for different configurations for various deployment stages.\n\n",
  "category": "Cloud",
  "userId": {
    "$oid": "6567e1e718cfd9fb550df1cf"
  },
  "author": {
    "name": "Admin User"
  },
  "updatedAt": null,
  "createdAt": {
    "$date": "2023-12-05T08:04:03.672Z"
  },
  "href": "deploying-a-single-page-application-(spa)-on-aws:-a-beginner's-guide.-part-7.-aws-app-runner",
  "__v": 0
},
{
  "_id": {
    "$oid": "656ed9cebbe1dec30053b6db"
  },
  "title": "IAM Programmatic access and AWS CLI 🚀 ☁",
  "photoUrl": "",
  "body": "IAM Programmatic access:-\nProgrammatic access in the context of AWS (Amazon Web Services) refers to the ability to interact with AWS services using code or scripts, rather than through the AWS Management Console. IAM (Identity and Access Management) is the service in AWS that enables you to manage access to AWS services and resources securely. When you want to enable programmatic access to AWS resources, you typically create IAM users and provide them with access keys.\n\nHere are the general steps to enable programmatic access using IAM:\n\nCreate an IAM User:\n\nSign in to the AWS Management Console.\n\nOpen the IAM console at https://console.aws.amazon.com/iam/.\n\nIn the navigation pane, choose \"Users\" and then \"Add user.\"\n\nEnter a username for the new IAM user.\n\nChoose the type of access this user will have (programmatic access, AWS Management Console access, or both).\n\nSet permissions for the user. You can either attach existing policies to the user or grant specific permissions.\n\nReview the user details and click \"Create user.\"\n\nAccess Key ID and Secret Access Key:\n\nOnce the user is created, you will be prompted to download a CSV file that contains the user's access key ID and secret access key. This information is crucial for programmatic access.\nStore Access Key ID and Secret Access Key Securely:\n\nEnsure that you store the access key ID and secret access key securely. Never share the secret key and avoid hardcoding it in your code.\nUse Access Key ID and Secret Access Key in Your Code:\n\nIn your code or scripts, you will use the access key ID and secret access key to authenticate requests to AWS services programmatically.\nAWS CLI:-\nThe AWS Command Line Interface (CLI) is a unified tool that provides a command-line interface for interacting with various AWS services. It allows you to manage and configure AWS services directly from the command line, making it a powerful and efficient tool for developers, system administrators, and other users who prefer command-line interfaces.\n\nHere are some key points and basic commands related to the AWS CLI:\n\nInstallation:\nYou need to install the AWS CLI on your local machine. You can find installation instructions for various operating systems here.\n\nConfiguration:\nAfter installation, you need to configure the AWS CLI with your AWS credentials. You can do this using the aws configure command, and you will be prompted to enter your AWS access key, secret key, region, and output format.\n\n\nCOPY\n\nCOPY\nbashCopy codeaws configure\nBasic Commands:\nList AWS S3 Buckets:\n\n\nCOPY\n\nCOPY\n bashCopy codeaws s3 ls\nCopy File to S3 Bucket:\n\n\nCOPY\n\nCOPY\n bashCopy codeaws s3 cp local-file.txt s3://your-bucket/\nList EC2 Instances:\n\n\nCOPY\n\nCOPY\n bashCopy codeaws ec2 describe-instances\nCreate an EC2 Key Pair:\n\n\nCOPY\n\nCOPY\n bashCopy codeaws ec2 create-key-pair --key-name your-key-name --query 'KeyMaterial' --output text > your-key-name.pem\nList Lambda Functions:\n\n\nCOPY\n\nCOPY\n bashCopy codeaws lambda list-functions\nDeploy to AWS Elastic Beanstalk:\n\nbashCopy codeaws elasticbeanstalk create-application-version --application-nam\n",
  "category": "Cloud",
  "userId": {
    "$oid": "6567e1e718cfd9fb550df1cf"
  },
  "author": {
    "name": "Admin User"
  },
  "updatedAt": null,
  "createdAt": {
    "$date": "2023-12-05T08:05:34.013Z"
  },
  "href": "iam-programmatic-access-and-aws-cli",
  "__v": 0
},
{
  "_id": {
    "$oid": "656eda68bbe1dec30053b6df"
  },
  "title": "Comprehensive Guide to Redux Toolkit: For Beginners",
  "photoUrl": "https://cdn.hashnode.com/res/hashnode/image/stock/unsplash/1SAnrIxw5OY/upload/82128f7f5511b58c9a585efeb4a27440.jpeg?w=1600&h=840&fit=crop&crop=entropy&auto=compress,format&format=webp",
  "body": "Introduction to Redux Toolkit\nBackground\nRedux has been a foundational library for managing state in complex JavaScript applications, especially with React. However, traditional Redux practices involve a substantial amount of boilerplate code. This has been a significant concern for developers, as managing numerous state transitions in large-scale applications becomes tedious. Additionally, integrating Redux with other necessary packages like redux-thunk for asynchronous actions and immer for handling nested state updates adds to the complexity.\n\nEmergence of Redux Toolkit\nTo address these issues and enhance the developer experience, the Redux Toolkit was introduced. As an official, opinionated, and comprehensive toolset, Redux Toolkit simplifies Redux development. It streamlines the setup process, covers common use cases, and integrates useful utilities, allowing developers to concentrate more on application-specific code rather than setup and configuration.\n\nCore Concepts of Redux\nBefore delving into Redux Toolkit, it's crucial to understand the core concepts of Redux:\n\nStore: The central place where your application's state is stored.\n\nState: The data your application maintains.\n\nActions: Objects that represent what happened and what needs to change in the application.\n\nReducers: Pure functions that take the previous state and an action, and return the next state.\n\nTraditional Redux Boilerplate\nIn traditional Redux, for each state transition, you need:\n\nAn action type constant.\n\nAn action object.\n\nAn action creator.\n\nA switch statement in a reducer.\n\n\nCOPY\n\nCOPY\n// Traditional Redux action and reducer\nconst ADD_TODO = 'ADD_TODO';\n\nfunction addTodoAction(todo) {\n  return {\n    type: ADD_TODO,\n    todo,\n  };\n}\n\nfunction todoReducer(state = [], action) {\n  switch (action.type) {\n    case ADD_TODO:\n      return [...state, action.todo];\n    default:\n      return state;\n  }\n}\nTransitioning to Redux Toolkit\nRedux Toolkit simplifies this process. It wraps around the core Redux functionalities, offering a more straightforward and less verbose approach.\n\nKey Features of Redux Toolkit:\nSimplifies Store Setup: Streamlines the creation of the Redux store.\n\nReduces Boilerplate: Automates action and reducer creation.\n\nBuilt-in Middleware: Includes Thunk middleware for async logic.\n\nDeveloper Tools: Integrates seamlessly with Redux DevTools.\nBy: Justine Mahinyila",
  "category": "Frontend",
  "userId": {
    "$oid": "6567e1e718cfd9fb550df1cf"
  },
  "author": {
    "name": "Admin User"
  },
  "updatedAt": null,
  "createdAt": {
    "$date": "2023-12-05T08:08:08.133Z"
  },
  "href": "comprehensive-guide-to-redux-toolkit:-for-beginners",
  "__v": 0
},
{
  "_id": {
    "$oid": "656edaf7bbe1dec30053b6e3"
  },
  "title": "Laravel Database Design & Structure",
  "photoUrl": "https://cdn.hashnode.com/res/hashnode/image/stock/unsplash/PkbZahEG2Ng/upload/e363dd172c58c35f6e0e0c119ceb8ef2.jpeg?w=1600&h=840&fit=crop&crop=entropy&auto=compress,format&format=webp",
  "body": "In my experiences, I saw most people struggling with database design and normalization, In the last 4/5 or years I guided many projects of my colleagues, friends, and younger brothers but they did not care about database designing and structuring.\n\nThey know about the CRUD operation in Laravel and they use it everywhere without knowing the database design and normalization.\n\nSuch as a CMS-based application that has many pages where the base columns are the same but they create a new table for each page, and they use the same CRUD operation for each table.\n\nan example for the about page they create a table named about and for the contact page they create a table named contact and so on.\n\nBut they don't know that they can use a single table for all the pages and they can use the same CRUD operation for all the pages.\n\nBasics of Database\nA basic knowledge of databases is very important to understanding database design and normalization.\n\nWhat is a Database\nA database is a collection of information that is organized so that it can be easily accessed, managed, and updated.\n\nThere are many types of databases, but the most common is the relational database or RDBMS. A relational database stores data in tables, which are organized into columns and rows. In a relational database, each row in the table is a record with a unique ID called the key. The columns of the table hold attributes of the data, and each record usually has a value for each attribute, making it easy to establish the relationships among data points.\n\nFor example, a company database may include tables for products, employees, and financial records. Each employee would be assigned a unique employee ID, which would be associated with information such as salary, job title, and contact information. The products table might include the product ID, product name, and quantity on hand. The financial tables would include information such as sales, expenses, and profits.\n\nWhat is Database Design\nDatabase design is the organization of data according to a database model. The designer determines what data must be stored and how the data elements interrelate. With this information, they can begin to fit the data into the database model.\n\nThe database design process starts with the requirement analysis and conceptual design phases. These phases are usually performed by a group of people with complementary skills (e.g., data analysts, systems analysts, and database designers). The conceptual design is typically performed by data analysts and systems analysts. The database designer is responsible for converting the conceptual design into a logical design, and then into a physical design.\n\nWhat is Database Normalization\nDatabase normalization is the process of structuring a database, usually a relational database, by a series of so-called normal forms to reduce data redundancy and improve data integrity.\n\nThere are several normal forms, from the first normal form (1NF) to the fifth normal form (5NF). Each normal form builds on the previous one.\n\nThe goal of normalization is to reduce and even eliminate data redundancy, an important consideration for application developers because it is incredibly difficult to store objects in a relational database that maintains the same information in several places.\n\nWhat is a Database Model\nA database model is a type of data model that determines the logical structure of a database and fundamentally determines in which manner data can be stored, organized and manipulated. The most popular example of a database model is the relational model, which uses a table-based format.\n\nThere are several different types of database models, including:\n\nHierarchical database model\n\nRelational model\n\nNetwork model\n\nObject-oriented database model\n\nEntity-relationship model\n\nDocument model\n\nEntity-attribute-value model\n\nStar schema\n\nThe object-relational model, which combines the two that make up its name\n\nDatabase in Laravel\nIn Laravel, we can use any database we want, but I prefer MySQL. In this article, I will use MySQL. If you want to use any other database, you can use it.\n\nLaravel provides a very simple way to create database tables. We need to create a migration file which will create a table in the database. Migration files are like version control for your database, allowing your team to easily modify and share the application's database schema. Laravel's database query builder provides a convenient, fluent interface for creating and manipulating database tables. It can be used to perform most database operations in your application and works on all supported database systems.\n\nIt is important to note that the Laravel Schema component is not a database abstraction layer. It doesn't replace the need for writing SQL statements, but it does provide a more expressive way of creating tables and columns. It also allows you to easily update your database schema from one version of your application to the next.\n\nDatabase Design\nIn database design, at first, we have to determine which kind of application we are going to build. Then we have to determine the entities of the application. Then we have to determine the attributes of the entities. Then we have to determine the relationships between the entities.\n\nI will use a simple blog application as an example.\nSo as a blog application, we will have the following entities.\n\nUsers\n\nPosts\n\nCategories\n\nTags\n\nComments\n\nIn those entities, Users will contain the information of the users or author. Posts will contain the information of the posts, created by the user. Categories will contain the information of the categories. Tags will contain the information of the tags. Comments will contain the information of the comments of the posts.\n\nNow we have to determine the attributes of the entities. We will have the following attributes in the entities.\n\nUsers\n\nid\n\nname\n\nemail\n\npassword\n\nremember_token\n\ncreated_at\n\nupdated_at\n\nPosts\n\nid\n\nuser_id\n\ncategory_id\n\ntitle\n\nslug\n\ncover_image\n\nbody\n\ncreated_at\n\nupdated_at\n\nCategories\n\nid\n\nname\n\nslug\n\ncreated_at\n\nupdated_at\n\nTags\n\nid\n\nname\n\nslug\n\ncreated_at\n\nupdated_at\n\nComments\n\nid\n\nuser_id\n\npost_id\n\nbody\n\ncreated_at\n\nupdated_at\n\nNow we have to determine the relationships between the entities. We will have the following relationships between the entities.\n\nUsers\n\nA user can have many posts.\n\nA user can have many comments.\n\nPosts\n\nA post belongs to a user.\n\nA post belongs to a category.\n\nA post can have many comments.\n\nA post can have many tags.\n\nCategories\n\nA category can have many posts.\nTags\n\nA tag can have many posts.\nComments\n\nA comment belongs to a user.\n\nA comment belongs to a post.\n\nSo this is the database design of our blog application. Now we will create the database structure.\n\nNB: Remember that, every table must have a primary key. In this article, I will use the id column as the primary key of the tables.\n\nIn database design and normalization, there are some basic rules and principles and it depends on the application you creating\n\nDatabase Structure\nNow we have designed our database. Let's create the database structure. We will use the Laravel migration tool to create the database structure.\n\nCreating the Models\nAt first, we will create the models and migration. We will create the models using the following command.\n\n\nCOPY\n\nCOPY\nphp artisan make:model User -m\nphp artisan make:model Post -m\nphp artisan make:model Category -m\nphp artisan make:model Tag -m\nphp artisan make:model Comment -m\nIt will create the models and migrations in the app/Models and database/migrations directory.\n\nMigrations schema and its explanation\nSo our migration files in the database/migrations directory, let’s update those.\n\ndatabase/migrations/create_users_table.php\n\nCOPY\n\nCOPY\nSchema::create('users', function (Blueprint $table) {\n    $table->id();\n    $table->string('name');\n    $table->string('email')->unique();\n    $table->timestamp('email_verified_at')->nullable();\n    $table->string('password');\n    $table->rememberToken();\n    $table->timestamps();\n});\nIn this schema, we have used the unique() method to make the email column unique. We have used the nullable() method to make the email_verified_at column nullable. We have used the rememberToken() method to create the remember_token column. We have used the timestamps() method to create the created_at and updated_at columns.\n\nHere you see, we have used respective column types, which is important for database design and normalization. The name, email and password column type is a string. The email_verified_at column type is timestamp. The remember_token column type is a string. The created_at and updated_at column type is timestamp.\n\nEvery time we create a migration, we have to create the respective column type, not just the string type or text type, also you need to define your column limit as necessary.\n\ndatabase/migrations/create_posts_table.php\n\nCOPY\n\nCOPY\nSchema::create('posts', function (Blueprint $table) {\n    $table->id();\n    $table->foreignId('user_id')->constrained()->onDelete('cascade');\n    $table->foreignId('category_id')->constrained()->onDelete('cascade');\n    $table->string('title');\n    $table->string('slug')->unique();\n    $table->string('cover_image', 255)->nullable();\n    $table->text('body');\n    $table->timestamps();\n});\nIn this table schema, we used two foreign keys user_id and category_id, and related to the users and categories table. In this schema, we have used the constrained() method to create the foreign key. We have used the onDelete('cascade') method to delete the posts when the user or category is deleted.\n\nMost of the time people use the unsignedBigInteger() method to create the foreign key, which works fine for the most part, but once we have some users and posts in our system - deleting a user will cause an issue (Attempt to read property \"users_table_column_name\" on null) because the foreign key constraint will fail. So we have to use the constrained() method to create the foreign key.\n\ndatabase/migrations/create_categories_table.php\n\nCOPY\n\nCOPY\nSchema::create('categories', function (Blueprint $table) {\n    $table->id();\n    $table->string('name');\n    $table->string('slug')->unique();\n    $table->timestamps();\n});\nThis is as simple as you see.\n\ndatabase/migrations/create_tags_table.php\n\nCOPY\n\nCOPY\nSchema::create('tags', function (Blueprint $table) {\n    $table->id();\n    $table->string('name');\n    $table->string('slug')->unique();\n    $table->timestamps();\n});\nThis is also simple as you see.\n\ndatabase/migrations/create_comments_table.php\n\nCOPY\n\nCOPY\nSchema::create('comments', function (Blueprint $table) {\n    $table->id();\n    $table->foreignId('user_id')->constrained()->onDelete('cascade');\n    $table->foreignId('post_id')->constrained()->onDelete('cascade');\n    $table->text('body');\n    $table->timestamps();\n});\nIn this table schema, we used two foreign key user_id and post_id, and related to the users and posts table.\n\nThe reason we use foreignId instead of unsignedBigInteger is because it's a shortcut for $table->unsignedBigInteger('user_id'); & $table->foreign('user_id')->references('id')->on('users'); and it's more readable. Also, we have used the onDelete('cascade') method to delete the comments when the user or post is deleted.\n\nCreating the foreign key indexes\nNow we have to create the foreign key indexes. We will create the foreign key indexes using the following code.\n\ndatabase/migrations/create_posts_table.php\n\n\nCOPY\n\nCOPY\nSchema::table('posts', function (Blueprint $table) {\n    $table->index('user_id');\n    $table->index('category_id');\n});\ndatabase/migrations/create_comments_table.php\n\n\nCOPY\n\nCOPY\nSchema::table('comments', function (Blueprint $table) {\n    $table->index('user_id');\n    $table->index('post_id');\n});\nCreating the pivot table\nNow we have to create the pivot table. We will create the pivot table using the following code.\n\n",
  "category": "Web Dev",
  "userId": {
    "$oid": "6567e1e718cfd9fb550df1cf"
  },
  "author": {
    "name": "Admin User"
  },
  "updatedAt": null,
  "createdAt": {
    "$date": "2023-12-05T08:10:31.905Z"
  },
  "href": "laravel-database-design-and-structure",
  "__v": 0
},
{
  "_id": {
    "$oid": "656edc6abbe1dec30053b6e7"
  },
  "title": "Why Material-Ui Reigns Supreme Over BootStrap in my React Adventures?",
  "photoUrl": "https://cdn.hashnode.com/res/hashnode/image/upload/v1701512847703/9b5f72f5-4831-47bd-b443-74fb5e179fa7.png?w=1600&h=840&fit=crop&crop=entropy&auto=compress,format&format=webp",
  "body": "Introduction:\nBootstrap and Material UI are two great CSS frameworks for developing websites to be more visually appealing. Both the CSS frameworks have a large community to improve continuously evolving the needs of web developers worldwide. They take all the CSS needs of front-end developers from simple buttons to the layout of the website to be responsive from big screen TV or Laptop screens to the small screen of Mobile phones. While each CSS framework has its unique way of working and allure, a closer look reveals contrasts in the design and assigns additional CSS to the existing CSS. In this blog post, we explore both CSS frameworks, exploring the distinctive features that set BootStrap and Material UI apart.\n\nThe Time-Honored: Bootstrap\nBootstrap, the front-end framework, was initially developed by Twitter and released as an open-source project in August 2011. It has five released versions till 2021. The Framework has gained widespread use in web development due to its ease of use and the responsive design it offers. As of Today, Bootstrap is the 17th most-starred project (4th most-starred library) on GitHub, with over 16k+ stars.\n\nBootstrap is an HTML, CSS, and JS library that simplifies the development of informative web pages. The basic purpose is to apply Bootstrap's choice of color, size, font, and layout for the website. They provide additional user interface elements such as dialog boxes, tooltips, progress bars, navigation drop-downs, and carousels.\n\nThe Trendsetting: Material UI\nMaterial-Ui, an open-source React component library, brings Google's Material Design to life effortlessly. With a rich assortment of prebuilt components, it's geared for immediate production use. Material Ui not only showcases aesthetic brilliance but also seamless customization, enabling the implementation of a personalized design system effortlessly. The Material UI is being used by popular companies such as Spotify, Amazon, NASA, NETFLIX, unity and shuttershock.\nThe Material-UI has undergone several updates and improvements continue due to its implementation of the Material Design principle and its ease of integration with React applications.\n\nThe Comparision of Bootstrap and Material UI using React JS:\nBootstrap and Material UI are two popular frontend frameworks for web app UIs, each with unique strengths and characteristics.\n\nDesign Philosophy :\nBootStrap\n\nIt follows a design philosophy that focuses on clean and minimalist design\n\nBest for the responsive and mobile-first approach and It provides a set of pre-designed components and styles.\n\nMaterial UI:\nGoogle's Material Design principles combine classic design with technology.\n\nThe components duplicate the physical world, with realistic shadows, transitions, and animations.\n\nIt provides an easy and visually appealing design out of the box\n\nComponent Style:\nBootstrap:\nIt has a unlike and recognizable bootstrap look.\n\nIt delivers a variety of pre-styled components such as buttons, forms, navigation bars, etc\n\nWhile customization is possible, achieving a distinctive look with Bootstrap requires substantial effort, as the default Bootstrap appearance tends to be easily recognizable unless considerable modifications are made.\n\nMaterial UI :\nThe components follow the Material Design style.\n\nThe components have a more modern and dynamic appearance with easy animations.\n\nIt provides a visually consistent screen size and a cohesive set of components strictly following Material Design guidelines.\n\nDependency :\nBootstrap:\n\nIt relies primarily on CSS and a little bit of jQuery for some interactive components.\n\nThe latest Bootstrap 5 version has notably decreased its dependence on jQuery compared to its early version\n\nMaterial UI:\nMaterial-UI is primarily designed for React, making it a perfect choice for React Applications.\n\nIt consists of both CSS-in-JS styles and boasts a robust theming system\n\nCommunity and Ecosystem:\nBootstrap:\nWith a sizable and well-established community, Bootstrap offers a lot of documentation and resources.\nIts popular adoption has cultivated a diverse ecosystem featuring a lot of themes, plugins, and extensions.\n\nMaterial UI:\nIt boasts a strong and increasing community, particularly within the realm of React.\nIt is maintained with care, and its components hassle-free integrate with the React application, contributing to its popularity and usability\n\nCode Comparison of Bootstrap and Material UI:\nMaterial UI Code in ReactJs :\nTo use the Material UI project local machine use the below command:\nnpm install @mui/material @emotion/react @emotion/styled\nReact Bootstrap in React JS:\nTo use the React Bootstrap project local machine use the below command:\nnpm install react-bootstrap bootstrap\n\nThe main app file\n\n\nCOPY\n\nCOPY\nimport React from 'react';\nimport Appbar from './AppBar';\n\nconst App = () => {\nreturn (\n<div>\n<Appbar/>\n</div>\n);\n};\nImport the Navbar from the Navbar file\n\n\nCOPY\n\nCOPY\nimport React from 'react';\nimport { Navbar, Nav } from 'react-bootstrap';\nimport {ReactComponent as Cart} from '../assets/Cart.svg'\nimport {ReactComponent as PersonIcon} from '../assets/PersonIcon.svg'\n\nconst Appbar = () => {\nreturn (\n<Navbar bg=\"dark\" variant=\"dark\" expand=\"lg\">\n<Navbar.Brand> \nTechCouture Haven</Navbar.Brand>\n<Navbar.Toggle aria-controls=\"basic-navbar-nav\" />\n<Navbar.Collapse id=\"basic-navbar-nav\">\n<Nav className=\"ml-auto\">\n<Nav.Link href=\"#home\">AllProducts</Nav.Link>\n<Nav.Link href=\"#link\">{Cart}</Nav.Link>\n<Nav.Link href=\"#person\">{PersonIcon}</Nav.Link>\n</Nav>\n</Navbar.Collapse>\n</Navbar>\n);\n};\nexport default Appbar;\nThe Conclusion:\nChoosing between Bootstrap and Material-Ui depends on your design choices, the visual style you want for your applications, and your similarity with the framework. Both are robust options, and the decision often comes down to the specific requirements and aesthetics of your projects. The bootstrap framework has fewer advantages compared to the Material UI, especially in the React JS library. The Material UI has more ease while changing the font styles, font colors, background, etc. But Bootstrap has less ease while changing these certain things. The Material UI is specially made for the React JS library compared to React Bootstrap. If you are back-end developer and don't want to know each nuance of CSS and JavaScript then choose Bootstrap in React or vice-versa.\nBy: Chaitanya Vankar",
  "category": "Frontend",
  "userId": {
    "$oid": "6567e1e718cfd9fb550df1cf"
  },
  "author": {
    "name": "Admin User"
  },
  "updatedAt": null,
  "createdAt": {
    "$date": "2023-12-05T08:16:42.479Z"
  },
  "href": "why-material-ui-reigns-supreme-over-bootstrap-in-my-react-adventures",
  "__v": 0
},
{
  "_id": {
    "$oid": "656edd97bbe1dec30053b6eb"
  },
  "title": "Basics of Asynchronous JS",
  "photoUrl": "",
  "body": "Hi Reader, nice to meet you! In this blog I will teach you about asynchronous JavaScript. It seems like such an important topic if you are studying JavaScript and It really is important !! . . . Of course you can go through docs or GeeksForGeeks but here I will try to make it very simple and clear to you with many examples. So, get on the ride ! ^ ^\nIf JavaScript is single threaded then how asynchronous?\nNow, before moving onto this question ( a pretty trick ques sometimes asked in interviews ) lets first understand what is this thing ! \" single threaded nature \" . No, its not related to actual thread :) 🧵( I wish it was ) ... Anyways -\n\nIt simply means that JavaScript has a one track mind. Like it can't do multitask. JavaScript executes code line by line. It will finish Task1, then move to task2 and then to task3..While other While other programming languages 📔allow for multiple threads to run simultaneously, each executing its own sequence of instructions,🛠️ JavaScript does not offer this capability.\nJust like, some person X cant cook while reading a book. Maybe he will first cook and then read or vice versa but can't do both together. Similarly, Js can't execute one function at the same time executing another function. This is single threaded nature. It's synchronous, but at times that can be harmful. For example, if a function takes awhile to execute or has to wait on something, it freezes everything up in the meanwhile.\n\nIf you want to know more about why Js don't have multithreading like other languages\n\nRead this..\n\nAsynchronous\nAsynchronous means its not synchronous (don't hate me for that line haha). But asynchronous in JS means codes executing parallelly, or not in any proper order.\nI know I know, we just learnt that JS is single threaded then why there is a thing called Async Js and how is it possible! We have a workaround...\n\nRole of Web browser\nLets take that example again, X is cooking and wants to read side by side. X can call his little brother and ask him to read out loud for him. At the same time, X cooks. Now, X is able to read while cooking. X is smart. Be like X, jk.\n\nIn layman language, there are certain functions recognized by JavaScript Engine that when it sees them, it hands off them to web browser to execute it in the background. For example,\n\nsetTimeout Function() - delay the code for given seconds or milliseconds and then runs the code which is inside the function",
  "category": "Programming Language",
  "userId": {
    "$oid": "6567e1e718cfd9fb550df1cf"
  },
  "author": {
    "name": "Admin User"
  },
  "updatedAt": null,
  "createdAt": {
    "$date": "2023-12-05T08:21:43.211Z"
  },
  "href": "basics-of-asynchronous-js",
  "__v": 0
},
{
  "_id": {
    "$oid": "656ee0c2bbe1dec30053b6ef"
  },
  "title": "Deep Dive in Git and GitHub for DevOps Engineers.",
  "photoUrl": "https://cdn.hashnode.com/res/hashnode/image/upload/v1700412979769/6237aa28-0e0e-4628-8154-0adaabd24e82.webp?w=1600&h=840&fit=crop&crop=entropy&auto=compress,format&format=webp",
  "body": "Q1. What is Git and why is it important?\nanswer :- Git is a distributed version control system (DVCS) used for tracking changes in source code during software development.\n\nhere are some key reason why git is important in the world of software development:\n\nVersion Control\n\nDistributed\n\nBranching\n\nMerging\n\nCommitting\n\nHistory and Log\n\nConflict Resolution\n\nStaging Area\n\nOpen Source\n\nQ2. What is the Difference Between main Branch and Master Branch?\nanswer :- The main difference between the \"master\" branch and the \"main\" branch (or whatever other name is used for the default branch) is essentially the name itself. These branches serve the same purpose: they are typically the default branch where the latest stable version of the code is found.\n\nQ3. Can you explain the difference between Git and GitHub?\nanswer :- Git is a version control system that manages and keeps track of your code. GitHub, on the other hand, is a service that let you host, share, and manage your code files on the internet. GitHub uses Git underneath, and lets you manage your Git repositories or folders easily on its platform.\n\nQ4. How do you create a new repository on GitHub?\nSign in to your GitHub account: If you don't have a GitHub account, you'll need to create one.\n\nOnce you're logged in, click on the \"+\" sign in the top right corner of the GitHub website\n\nIn the dropdown menu, select \"New repository.\"\n\nYou will be taken to the \"Create a new repository\" page. Here, you'll need to provide the following information for your new repository:\n\na. Repository name: Choose a name for your repository. This should be unique within your GitHub account.\n\nb. Description (optional): Provide a brief description of your repository to help others understand its purpose.\n\nc. Visibility: You can choose to make the repository public (visible to everyone) or private (visible only to those with access).\n\nd. Initialize this repository with a README: If you want to create a README file for your repository, check this option. A README file is helpful for providing information about your project.\n\n5 You can also choose to add a .gitignore file (specifies which files or directories should be ignored by Git) and a license file (specifies the licensing terms for your project).\n\n6 Once you've filled in the required information and made any additional selections, click the \"Create repository\" button.\n\nYour new GitHub repository will be created with the specified settings, and you'll be redirected to the repository's page. From there, you can start adding files, committing changes, and collaborating with others on your project.\n\nQ5.What is difference between local & remote repository? How to connect local to remote?\nanswer :- A local repository is on the local machine - much like the keyboard attached to a computer is local to that computer.\n\nLikewise, a remote repository is a repository on some other machine which is remote to a given local machine.\n\nTo add a new remote, use the git remote add command on the terminal, in the directory your repository is stored at.",
  "category": "Other",
  "userId": {
    "$oid": "6567e1e718cfd9fb550df1cf"
  },
  "author": {
    "name": "Admin User"
  },
  "updatedAt": null,
  "createdAt": {
    "$date": "2023-12-05T08:35:14.080Z"
  },
  "href": "deep-dive-in-git-and-github-for-devops-engineers.",
  "__v": 0
},
{
  "_id": {
    "$oid": "656ee17abbe1dec30053bb6b"
  },
  "title": "Understanding TypeScript Generics",
  "photoUrl": "",
  "body": "Generics:\n\nGenerics in TypeScript enable the creation of flexible and reusable functions or components that work seamlessly with various data types, enhancing code type safety and maintainability.\n\nExample 1: Without Generics\n\n\nCOPY\n\nCOPY\n// Without Generics\nfunction echo(input: any): any {\n  return input;\n}\n\nconst result1 = echo(42);       // result1 is of type 'any'\nconst result2 = echo(\"Hello\");  // result2 is of type 'any'\nExample 2: Using Generics\n\n\nCOPY\n\nCOPY\n// Using Generics\nfunction betterEcho<Type>(input: Type): Type {\n  return input;\n}\n\nconst betterResult1 = betterEcho(42);       // betterResult1 is of type 'number'\nconst betterResult2 = betterEcho(\"Hello\");  // betterResult2 is of type 'string'\nKey Points:\n\nThe echo function without generics uses the any type, which can lead to a loss of type information.\n\nThe betterEcho function uses generics <Type> to maintain the type of the input, providing better type safety.\n\nWhen calling betterEcho(42), TypeScript infers the type as number, and when calling betterEcho(\"Hello\"), it infers the type as string.\n\nUsing generics ensures that the output type is the same as the input type, enhancing code reliability and developer experience.\n\nStay tuned for more TypeScript insights and practical tips!\nBY: Abdul Shaik",
  "category": "Programming Language",
  "userId": {
    "$oid": "6567e1e718cfd9fb550df1cf"
  },
  "author": {
    "name": "Admin User"
  },
  "updatedAt": null,
  "createdAt": {
    "$date": "2023-12-05T08:38:18.336Z"
  },
  "href": "understanding-typescript-generics",
  "__v": 0
},
{
  "_id": {
    "$oid": "656ee1cebbe1dec30053bb6f"
  },
  "title": "Plop.js Demystified",
  "photoUrl": "https://cdn.hashnode.com/res/hashnode/image/upload/v1701691768330/e7100c4c-9f79-4597-86db-b689ffda08ec.jpeg?w=1600&h=840&fit=crop&crop=entropy&auto=compress,format&format=webp",
  "body": "Let’s imagine your’re playing with lego blocks 🧱 and you have a set of pieces that when are added in the right place a castle 🏰 is created . Now each time you want to build that castle to show off to your friends you to have again find those specific pices and put them together in the same way . It takes time right ? 🥲\n\nNow imagine you have a magic wand 🪄 , You say the spell to it “Build my castle” you magic wand already knows which pieces to be used and how to put them together to build that castle for you . So , it builds that instantly ! That’s what my friend Plop.js does! 😗\n\nIn a world of coding , instead of building castles we build pieces of code like web pages or parts of a website . These pieces are often build in the same way. So in the coding world Plop.js is our magic wand 🪄 We tell it what piece of code we want to build and it puts it together for us. Isn’t that cool ?\n\nNow let’s look at and example . Let’s say we want to build a piece of code that’s like a little castle , but in coding terms we call it a ‘component’ . Here is how we can do it using Plop.js :\n\n\nCOPY\n\nCOPY\n// This file is our magic wand , or in coding terms a \"plopfile.js\"\n\nmodule.exports = function(plop) {\n// we will tell the magic wand how to build our little castle or 'component'\n  plop.setGenerator('component',{\n  description : 'Create a new component',\n  // The magic will ask us some questions before it starts building \n\n  prompts : [{\n      type: 'input',\n      name: 'name',\n      message : 'What is your component name ?',\n  }],\n  // The the magic will start building our component based on our answers\n  actions: [{\n         tyep:'add',\n         path: 'src/components/{{name}}/index.js'\n         templateFile: '.src/component/**',\n        }]\n  });\n};\nIn the above case our magic(Plop.js) will ask us for the name of our component ( our little castle).Then it will create a new file with that name in right place src/component/{{name}}/index.js\n\nAnd think of the templateFile is like the blueprint of our little castle, it tells the magic wand how to put the pieces together.\n\nIsn’t that fun ? Just like playing lego blocks, but in the coding world ✌️.\n\nBy: Jatin Dixit",
  "category": "Frontend",
  "userId": {
    "$oid": "6567e1e718cfd9fb550df1cf"
  },
  "author": {
    "name": "Admin User"
  },
  "updatedAt": null,
  "createdAt": {
    "$date": "2023-12-05T08:39:42.467Z"
  },
  "href": "plop.js-demystified",
  "__v": 0
},
{
  "_id": {
    "$oid": "656ee6adbbe1dec30053bb87"
  },
  "title": "Host a FullStack -NodeJs & a React App on Render, Netlify using Github for FREE",
  "photoUrl": "",
  "body": "Deploying a NodeJs, Express and a React App\nI recently learned a way to host our MERN stack projects using free resources like Render and Netlify. For more reading please go through the references at the end.\n\nHosting your backend on Render and your frontend on Netlify is a common setup that many developers use for their web applications. Below are the steps to guide you through this process:\n\nStep 1: Set Up Your Environment\nFirst, let’s make sure the necessary tools are installed before we deploy our app.\n\nNode.js and npm:\nDownload and install Node.js from the official website.\n\nNpm comes bundled with Node.js.\n\n2. Git:\n\nDownload Git from the official website. This version control system will help you keep track of changes to your code.\n3. Code Editor:\n\nChoose a code editor that suits your preferences. Visual Studio Code is recommended due to its popularity, ease of use, and extensive features.\n4. Express.js:\n\nInstall Express.js using npm by running the following command in your terminal:\n\nCOPY\n\nCOPY\nnpm install express\nStep 2: Prepare Your Application for Development\nNavigate to Your Project Folder:\nOpen the terminal and navigate to your project folder by typing\n\n\nCOPY\n\nCOPY\n  cd path/to/your/folder\n2. Start Development Servers:\n\nEnsure that both the client and server of your application are ready for development. Open separate terminals for the server and client.\n\nNavigate to the server path and run the server. Ensure it’s connected to your database and listening on the specified port.\n\nMake sure your client is accessible through the browser on your localhost.\n\n\n\nEx : Folder Structure\n\n\n\nEx: Github repository\n\nYou can find the project and github repository where I have two separate folders for backend(server) and frontend(client).\n\nWe have to deploy these folders separately.\n\nFirst let’s host our backend.\n\nStep 3: Set Up Your Backend on Render\nCreate a Render Account:\nVisit Render and sign up for an account if you don’t have one.\n2. Create a New Web Service:\n\nOnce logged in, click on the “New+” button on your Render dashboard.\n\nSelect “Web Service” and Build and deploy from Git repository.\n\n\n\nChoose Web service option.\n\n\n\nBuild and Deploy from Git repo\n\n3. Configure Your Backend Service:\n\nUse your GitHub repository for the existing project. Grant Render access to the repository.\n\nThen connect Github and select your repository. (Refer the guide on connecting Github repositories to Render- https://render.com/docs/github ).\n\n\n\nDetails for deployment\n\n4. Configure Build Settings:\n\nSpecify the root directory for your backend. In your case, since the backend is in the root directory, leave it empty or set it to /.\n\nCheck your project’s package.json file for the correct build command. If it's npm run build, use that command. Also, check for the start command in the scripts section of your package.json file and provide that information.\n\n\n\nGit branch & Root directory\n\n\n\nBuild and Start commands\n\n\n\nEx : Compare commands with package.json\n\n5. Configure Environment Variables:\n\nSet any environment variables your backend needs, such as database credentials or API keys. You can do this in the “Environment” section of your Render service settings.\n\nSpecifically, add the MONGO_URL and PORT environment variables.",
  "category": "FullStack",
  "userId": {
    "$oid": "6567e1e718cfd9fb550df1cf"
  },
  "author": {
    "name": "Admin User"
  },
  "updatedAt": null,
  "createdAt": {
    "$date": "2023-12-05T09:00:29.016Z"
  },
  "href": "host-a-fullstack-nodejs-and-a-react-app-on-render-netlify-using-github-for-free",
  "__v": 0
},
{
  "_id": {
    "$oid": "656ee6ebbbe1dec30053bba2"
  },
  "title": "Deploy an End-to-End IoT ApplicationDeploy an End-to-End IoT Application",
  "photoUrl": "",
  "body": "In this AWS Skills Builder lab I've connected virtual things using AWS IoT, published messages and visualised real-time data using a serverless web application leveraging AWS Lambda, Amazon API Gateway and Amazon S3.\n\nThe steps in this lab includes:\n\nSet up AWS IoT\n\nCreate an IoT thing, policy, and certificate\n\nRun a device simulator on Amazon EC2\n\nProcess and Visualise streaming data using a serverless app\n\nThere are few components that need to be created:\n\nThing – A thing is a logical representation of a device stored in IoT’s Registry.\n\nPolicy – You attach a policy to a certificate to dictate what the Thing is entitled to do on AWS IoT.\n\nCertificates – Certificates are used for authentication. Things can communicate with AWS IoT via MQTT which is a machine-to-machine pub-sub protocol well-suited for IoT use cases given its low overhead and low resource requirements.\n\nRule – Rules leverages AWS IoT’s Rules Engine to dictate how messages sent from Things to AWS IoT are handled.\n\nI launched an EC2 which has a Python app which acts a simulator for an IoT device that generates and sends different metrics to AWS IoT.\n\nThis EC2 instance had the appropriate credentials granted by the certificate to be allowed into AWS services, the messages sent by the simulator are filtered by a Rule and stored in DynamoDB table.\n\nAfter running the simulator for few minutes, the messages started to appear on the table ready to be retrieved using API Gateway endpoint for authorised services.\n\nThe next step was to deploy static website hosted in S3, it retrieved the data from DynamoDB using API Gateway and visualised it in graphs.\n\nAs a conclusion, in this lab I've deployed a simulated IoT Thing, stored and visualised the sent metrics. I've had the chance to play around AWS IoT core service, DynamoDB, API Gateway, S3 and touches of Amazon Linux.\n\n\n\n\n\n\n",
  "category": "Other",
  "userId": {
    "$oid": "6567e1e718cfd9fb550df1cf"
  },
  "author": {
    "name": "Admin User"
  },
  "updatedAt": null,
  "createdAt": {
    "$date": "2023-12-05T09:01:31.262Z"
  },
  "href": "deploy-an-end-to-end-iot-applicationdeploy-an-end-to-end-iot-application",
  "__v": 0
},
{
  "_id": {
    "$oid": "656ee749bbe1dec30053bba6"
  },
  "title": "https://blog.rakeshkatti.in/personalized-ai-exploring-custom-gpts",
  "photoUrl": "https://cdn.hashnode.com/res/hashnode/image/upload/v1701461652525/464fff07-5ac4-415a-8fcd-860c3ee32c84.jpeg?w=1600&h=840&fit=crop&crop=entropy&auto=compress,format&format=webp",
  "body": "Introduction\nIn the ever-evolving landscape of artificial intelligence, OpenAI recently introduced a groundbreaking development just a few days before the boardroom drama: 'Custom GPTs', a version of ChatGPT, or simply what they call 'GPTs'. Over the last couple of weeks, I have been delving into the potential of these customized GPTs. Meanwhile, Amazon has also launched a similar feature called PartyRock. This blog is the first in a multi-part series where we will explore what customized GPTs are and their potential use cases, In the coming parts we will be exploring how to create a custom GPT along with some of the custom GPTs I have developed in the process.\n\nProblem\nChatGPT, which uses Large Language Models(LLM) like GPT-4 or GPT-3.5, is already one of the most powerful AI tools, used by millions of end-users every day. When interacting with ChatGPT, they often need to provide extensive context in their prompts or follow up with multiple prompts to extract the desired or optimal output. This can be time-consuming, especially for those seeking quick and precise answers.\n\nSmall applications built using APIs on top of GPT models must create pre-trained models that incorporate the necessary context and data specific to their application's focus.\n\nThis involves not just mastering the art of prompt engineering but also managing the costs associated with these models. Using GPT-4 costs approximately $0.06 per 1,000 tokens.\n\nWhat are Custom GPTs\nCustom GPTs represent a new approach to creating mini GPTs tailored for specific use cases.\n\nCustom GPTs can be as simple as using your already saved prompts that you reuse daily. By providing these as a context, they function as a form of custom GPT, enabling users to quickly obtain the results they need without repetitive prompting.\n\nUsers also gain the ability to store context and upload significant amounts of data, up to 20 knowledge files of 512 MB each. This feature is particularly beneficial for small applications and power users, providing the necessary depth of data for more specialized and accurate results.\n\nWhat truly makes Custom GPTs remarkable is their accessibility. The creation of a custom GPT isn't limited to developers or tech experts. OpenAI has democratized the GPT creation process, allowing all end users to craft their own Custom GPTs. This is facilitated by the GPT builder, a tool that simplifies the process, requiring users to provide just a prompt to begin creating their personalized AI model. More details about this will be discussed in later sections.\n\n\n\nGPTs Store\n💡\niPhone is to ChatGPT, App Store is to Custom GPTs\nCurrently, despite the presence of multiple models like BERT, Claude, PaLM, and LLaMA, GPT-4 has emerged as the most reliable choice in the GenAI landscape and for projects built on top of LLMs. Many likened ChatGPT's unveiling last year to an 'iPhone moment' in the AI industry when it reached a million users in just 5 days.\n\nBut how exactly do these mini GPTs compare to the App Store? As of now, you can access Custom GPTs via a direct URL, and some popular GPTs are featured on the discovery page which can be found by clicking on Explore in the sidebar. OpenAI will soon be launching a GPT Store. This platform will enable not only the sharing of custom GPTs but also provide creators with the opportunity to monetize their models through a revenue-sharing model. This initiative is expected to boost the development of GPTs, similar to how mobile app development surged in the past.\n\n\n\nPractical Applications and Benefits of Custom GPTs\nWhere can we use Custom GPT? Listing down some of the usecases I can think of, along with some usecases I have encountered while exploring GPTs created by other users.\n\nDisclaimer: I understand many of these can also be created by building a pretrained models on top of other LLMs. I'm just trying to list down the ones that can be built with GPT Builder via prompts and knowledge files.\n\nOrganization Use Cases\nCustomer Service and FAQs: Companies can upload their entire FAQ database to a custom GPT. Then, this custom GPT can be shared via a URL, or it can be integrated into the company's bot for better customer service.\n\nInternal HR Bot: Companies often have a ton of HR policies. By uploading all these policies and creating a custom GPT, employees can gain quick and easy access to the information they need. (But yeah need to ensure the information is accessible only to employees)\n\nData Analysis: We can train the custom GPT model to recognize and analyze data, thereby providing insights that aid in faster and more accurate decision-making. This approach is particularly helpful for businesses that need to understand complex data, ultimately enhancing operational efficiency.\n\nGeneral Use Cases\nCooking and Recipe Generation: Create a GPT model trained in culinary arts, incorporating a wide array of recipes from around the world. This model, when given a list of available ingredients, could quickly suggest multiple recipes.\n\nEducational Tools: Custom GPTs can be tailored to specific educational subjects or languages. Imagine a GPT model fine-tuned with particular textbooks or subjects, assisting students in understanding complex concepts or practicing a new language.\n\nLegal and Medical Assistance: Lawyers and medical professionals often need quick access to a wealth of references. Custom GPTs, fine-tuned with legal or medical texts, can aid these professionals by providing rapid references and suggestions based on specialized knowledge bases.\n\nTravel Planner: By training a custom GPT with the best travel itineraries as knowledge files, users can receive tailor-made holiday suggestions based on their preferences.\n\nAgricultural Advisor: A custom GPT could be trained with regional weather patterns and market demands to provide farmers with insights about the most suitable crops for a given season and market.\n\nFinance Planning: Customized to individual financial situations and goals, a custom GPT could offer advice on budgeting, investment strategies, and retirement planning.\n\nCopy Checker: We can have a custom GPT designed to assist with everyday writing. Its primary function isn't to change sentences but to check for spelling and grammatical errors. This tool would be invaluable for enhancing our day-to-day written communications, including social media posts, emails, blogs, and more, ensuring they are polished and professional.\n\nBy: Rakesh Katti",
  "category": "AI",
  "userId": {
    "$oid": "6567e1e718cfd9fb550df1cf"
  },
  "author": {
    "name": "Admin User"
  },
  "updatedAt": null,
  "createdAt": {
    "$date": "2023-12-05T09:03:05.182Z"
  },
  "href": "https:blog.rakeshkatti.inpersonalized-ai-exploring-custom-gpts",
  "__v": 0
}]